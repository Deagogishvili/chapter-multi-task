{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bf4c1f-c19c-4092-9cae-5900ea389bb0",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557b895b-8550-4a87-8c4b-3babe4a9daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re \n",
    "import urllib.request\n",
    "import json\n",
    "import os \n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b26ee-61ac-4e95-9909-19e2d883c000",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65dbce-5daa-4254-9567-18563412ea40",
   "metadata": {},
   "source": [
    "Google drive = https://drive.google.com/drive/folders/17z34rgAw2nz4ywlF2G4CTJifcAI66lka?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5957f329-1988-42c7-b087-1804372b0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.getcwd()) + '/data/'\n",
    "figure_path = os.path.dirname(os.getcwd()) + '/figures'\n",
    "url_template = 'http://www.rcsb.org/pdb/files/{}.pdb'\n",
    "rest_url='https://www3.cmbi.umcn.nl/xssp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f1e32-8b46-4324-b41a-5120773d35f8",
   "metadata": {},
   "source": [
    "# Imort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e4dc54-3031-4cce-8aa0-2bc22512c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_file=pd.read_csv(data_path + 'expression/expression.csv')\n",
    "expression=dict(zip(list(expression_file.PDB_ID),list(expression_file.Expression)))\n",
    "species=dict(zip(list(expression_file.PDB_ID),list(expression_file.Species)))\n",
    "patches = os.listdir(data_path + 'patches/raw')\n",
    "\n",
    "AA = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "HYDR = ['A','C','F','I','L','M','V','W','Y']\n",
    "SPEC = dict(zip(list(expression_file.Species.value_counts().index[:10]),range(0,10)))\n",
    "EXP = np.percentile(expression_file[~expression_file.Expression.isnull()].Expression, np.arange(0,100,10)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771f7516-722f-44e6-9227-9ef877138f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_uniprot(pdbid):\n",
    "    try:\n",
    "        protein=pdbid\n",
    "        url = url_template.format(protein.upper()[:4])\n",
    "        response = urllib.request.urlopen(url)\n",
    "        pdb = response.read().decode('utf-8')\n",
    "        response.close()\n",
    "        m = re.search('UNP\\ +(\\w+)', pdb)\n",
    "        return m.group(1)  \n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58105d5c-1993-4278-8b55-2a0999bb9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ASA(data, list_data, agg_data=None):\n",
    "    #num_columns = 97 if agg_data is not None else 95\n",
    "    new_data=np.zeros((len(data),len(data[0]),97))\n",
    "    \n",
    "    print(new_data.shape, 'initial')\n",
    "    for i in tqdm(range(len(data))):\n",
    "        #Column len(AA)\n",
    "        column=np.zeros((len(data[i]),27))\n",
    "        mask = np.count_nonzero(data[i,:,50])\n",
    "        \n",
    "        #Column 0 equals TASA = sum(RSA*ASAmax)\n",
    "        tasa=sum(data[i,:,53]*data[i,:,50])\n",
    "        hydr=[bool(AA[k] in HYDR) for k in np.argmax(data[i,:,:20],axis=-1)]\n",
    "        #Column 1 equals THSA = sum(RSA*ASAmax*hydr_mask)\n",
    "        thsa=sum(data[i,:,53]*data[i,:,50]*hydr)\n",
    "        #Column 2 equals RHSA = sum(RSA*ASAmax*hydr_mask)/sum(RSA*ASAmax)\n",
    "        rhsa=thsa/tasa\n",
    "        column[0,0]=round(tasa,1)\n",
    "        column[0,1]=round(thsa,1)\n",
    "        column[0,2]=round(rhsa,5)\n",
    "\n",
    "        #Column 3 equals Patch Size\n",
    "        id_patch=list_data[i].replace('-','').upper()\n",
    "        if id_patch+'.csv' in patches: \n",
    "            patch_info = pd.read_csv(os.path.join(data_path + 'patches','raw',f'{id_patch}.csv'))\n",
    "            # Checking if we can find a match between our two files\n",
    "            data_fasta = ''.join([AA[k] for k in np.argmax(data[i,:mask,:20],axis=-1)])\n",
    "            patch_fasta = ''.join(list(patch_info.residue))\n",
    "            s = SequenceMatcher(None, patch_fasta, data_fasta)\n",
    "            Match = s.find_longest_match(0, len(patch_fasta), 0, len(data_fasta))\n",
    "            if Match.size/max(len(data_fasta),len(patch_fasta))>0.8:                \n",
    "                patch_column = np.nan_to_num(np.array(list(patch_info.patch_size)))\n",
    "                patch_place = np.zeros((len(data[i])))\n",
    "                patch_place[Match.b:Match.b+Match.size] = patch_column[Match.a:Match.a+Match.size]\n",
    "                column[:,4]=np.where(patch_place>0,1,0)\n",
    "                if not((patch_place==0).all()):\n",
    "                    column[0,3]=round(max(patch_place),1)\n",
    "                    column[:,5]=np.where(patch_place==max(patch_place),1,0)\n",
    "\n",
    "        #Column 6 equals Species\n",
    "        if list_data[i] in species.keys() and species[list_data[i]] in SPEC.keys():\n",
    "            column[0,6+SPEC[species[list_data[i]]]]=1\n",
    "\n",
    "        # Columns 17 equals expression\n",
    "        if list_data[i] in expression.keys() and not(np.isnan(expression[list_data[i]])):\n",
    "            expression_value=round(expression[list_data[i]],1)  \n",
    "            column[0,16]=expression_value\n",
    "            rk=0\n",
    "            for k in EXP[1:]:\n",
    "                if expression_value>=k:\n",
    "                    rk+=1\n",
    "            column[0,17+rk]=1    \n",
    "        padding_zero = np.zeros((len(data[i]),2))  \n",
    "        column = np.c_[column,padding_zero]\n",
    "        new_data[i]=np.c_[data[i],column]        \n",
    "    \n",
    "    print(new_data.shape, 'final')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da19142-865b-4123-a7d9-ab37c914fd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 1632, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10848/10848 [00:48<00:00, 222.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 1632, 97) final\n",
      "(21, 1494, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 242.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1494, 97) final\n",
      "(513, 874, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:01<00:00, 277.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 874, 97) final\n",
      "(115, 1111, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 280.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 1111, 97) final\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    name_train,name_casp,name_cb,name_ts=np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/Train_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CASP12_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CB513_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/TS115_HHblits.npz\")['pdbids']\n",
    "    data_train,data_casp,data_cb,data_ts=np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/Train_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CASP12_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CB513_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/TS115_HHblits.npz\")['data']\n",
    "    list_train, list_casp,list_cb,list_ts=get_ASA(data_train,name_train),get_ASA(data_casp,name_casp),get_ASA(data_cb,name_cb),get_ASA(data_ts,name_ts)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Train_HHblits_extended.npz',pdbids=name_train,data=list_train)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CASP12_HHblits_extended.npz',pdbids=name_casp,data=list_casp)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CB513_HHblits_extended.npz',pdbids=name_cb,data=list_cb)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/TS115_HHblits_extended.npz',pdbids=name_ts,data=list_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8d6236-614c-4755-b826-3b7d8c4b7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 1632, 68)\n",
      "(21, 1494, 68)\n",
      "(513, 874, 68)\n",
      "(115, 1111, 68)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_casp.shape)\n",
    "print(data_cb.shape)\n",
    "print(data_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e58e1-a0c6-4811-b0af-c02c6e1593d7",
   "metadata": {},
   "source": [
    "# Save separate csv files containing THSA RHSA and LHP only for a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2888e2e5-980f-4fa0-8a6b-a52d5cf06605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_save_list_dataset(input_path, output_csv_path):\n",
    "    # Load the extended dataset\n",
    "    extended_data = np.load(input_path)\n",
    "    \n",
    "    # Extract data and pdbids\n",
    "    data = extended_data['data']\n",
    "    pdbids = extended_data['pdbids']\n",
    "    \n",
    "    # Assuming the columns 69, 70, and 71 correspond to THSA, RHSA, and LHP\n",
    "    thsa_list = [data[i, 0, 69] for i in range(data.shape[0])]\n",
    "    rhsa_list = [data[i, 0, 70] for i in range(data.shape[0])]\n",
    "    lhp_list = [data[i, 0, 71] for i in range(data.shape[0])]\n",
    "    \n",
    "    # Create a DataFrame with PDB IDs and lists\n",
    "    df = pd.DataFrame({'PDB_ID': pdbids, 'THSA': thsa_list, 'RHSA': rhsa_list, 'LHP': lhp_list})\n",
    "    \n",
    "    # Save DataFrame as a CSV file\n",
    "    df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97382846-c1ba-4bf1-ae3a-7fef8dc3b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_and_save_list_dataset('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Train_HHblits_extended.npz', \n",
    "                              data_path + 'patches/Train_LHP.csv')\n",
    "extract_and_save_list_dataset('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CASP12_HHblits_extended.npz', \n",
    "                              data_path + 'patches/CASP12_LHP.csv')\n",
    "extract_and_save_list_dataset('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CB513_HHblits_extended.npz', \n",
    "                              data_path + 'patches/CB513_LHP.csv')\n",
    "extract_and_save_list_dataset('/Users/deagogishvili/Documents/PhD/multitask/data/extended/TS115_HHblits_extended.npz', \n",
    "                              data_path + 'patches/TS115_LHP.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
