{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bf4c1f-c19c-4092-9cae-5900ea389bb0",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557b895b-8550-4a87-8c4b-3babe4a9daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re \n",
    "import urllib.request\n",
    "import json\n",
    "import os \n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b26ee-61ac-4e95-9909-19e2d883c000",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65dbce-5daa-4254-9567-18563412ea40",
   "metadata": {},
   "source": [
    "Google drive = https://drive.google.com/drive/folders/17z34rgAw2nz4ywlF2G4CTJifcAI66lka?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5957f329-1988-42c7-b087-1804372b0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.getcwd()) + '/data/'\n",
    "figure_path = os.path.dirname(os.getcwd()) + '/figures'\n",
    "url_template = 'http://www.rcsb.org/pdb/files/{}.pdb'\n",
    "rest_url='https://www3.cmbi.umcn.nl/xssp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f1e32-8b46-4324-b41a-5120773d35f8",
   "metadata": {},
   "source": [
    "# Imort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b130d2ad-32a1-4e79-9c9a-127c1ad53348",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_train = pd.read_csv(data_path + '/aggregation/AggBERT_train.csv')\n",
    "aggregation_test = pd.read_csv(data_path + '/aggregation/AggBERT_test.csv')\n",
    "aggregation_train['Classification'] = np.where(aggregation_train['label']==1, 'amyloid', 'non-amyloid')\n",
    "aggregation_train['PDB_ID'] = aggregation_train['Sequence'] + '.pdb'\n",
    "aggregation_test['Classification'] = np.where(aggregation_test['label']==1, 'amyloid', 'non-amyloid')\n",
    "aggregation_test['PDB_ID'] = aggregation_test['Sequence'] + '.pdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e4dc54-3031-4cce-8aa0-2bc22512c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_file=pd.read_csv(data_path + '/expression/expression.csv')\n",
    "expression=dict(zip(list(expression_file.PDB_ID),list(expression_file.Expression)))\n",
    "species=dict(zip(list(expression_file.PDB_ID),list(expression_file.Species)))\n",
    "patches = os.listdir(data_path + 'patches/raw')\n",
    "\n",
    "AA = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "HYDR = ['A','C','F','I','L','M','V','W','Y']\n",
    "SPEC = dict(zip(list(expression_file.Species.value_counts().index[:10]),range(0,10)))\n",
    "EXP = np.percentile(expression_file[~expression_file.Expression.isnull()].Expression, np.arange(0,100,10)).tolist()\n",
    "AGG = dict(zip(list(aggregation_train.Classification.value_counts().index[:2]),range(0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771f7516-722f-44e6-9227-9ef877138f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_uniprot(pdbid):\n",
    "    try:\n",
    "        protein=pdbid\n",
    "        url = url_template.format(protein.upper()[:4])\n",
    "        response = urllib.request.urlopen(url)\n",
    "        pdb = response.read().decode('utf-8')\n",
    "        response.close()\n",
    "        m = re.search('UNP\\ +(\\w+)', pdb)\n",
    "        return m.group(1)  \n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58105d5c-1993-4278-8b55-2a0999bb9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ASA(data, list_data, agg_data=None):\n",
    "    #num_columns = 97 if agg_data is not None else 95\n",
    "    new_data=np.zeros((len(data),len(data[0]),97))\n",
    "    \n",
    "    print(new_data.shape, 'initial')\n",
    "    for i in tqdm(range(len(data))):\n",
    "        #Column len(AA)\n",
    "        column=np.zeros((len(data[i]),27))\n",
    "        mask = np.count_nonzero(data[i,:,50])\n",
    "        \n",
    "        #Column 0 equals TASA = sum(RSA*ASAmax)\n",
    "        tasa=sum(data[i,:,53]*data[i,:,50])\n",
    "        hydr=[bool(AA[k] in HYDR) for k in np.argmax(data[i,:,:20],axis=-1)]\n",
    "        #Column 1 equals THSA = sum(RSA*ASAmax*hydr_mask)\n",
    "        thsa=sum(data[i,:,53]*data[i,:,50]*hydr)\n",
    "        #Column 2 equals RHSA = sum(RSA*ASAmax*hydr_mask)/sum(RSA*ASAmax)\n",
    "        rhsa=thsa/tasa\n",
    "        column[0,0]=round(tasa,1)\n",
    "        column[0,1]=round(thsa,1)\n",
    "        column[0,2]=round(rhsa,5)\n",
    "\n",
    "        #Column 3 equals Patch Size\n",
    "        id_patch=list_data[i].replace('-','').upper()\n",
    "        if id_patch+'.csv' in patches: \n",
    "            patch_info = pd.read_csv(os.path.join(data_path + 'patches','raw',f'{id_patch}.csv'))\n",
    "            # Checking if we can find a match between our two files\n",
    "            data_fasta = ''.join([AA[k] for k in np.argmax(data[i,:mask,:20],axis=-1)])\n",
    "            patch_fasta = ''.join(list(patch_info.residue))\n",
    "            s = SequenceMatcher(None, patch_fasta, data_fasta)\n",
    "            Match = s.find_longest_match(0, len(patch_fasta), 0, len(data_fasta))\n",
    "            if Match.size/max(len(data_fasta),len(patch_fasta))>0.8:                \n",
    "                patch_column = np.nan_to_num(np.array(list(patch_info.patch_size)))\n",
    "                patch_place = np.zeros((len(data[i])))\n",
    "                patch_place[Match.b:Match.b+Match.size] = patch_column[Match.a:Match.a+Match.size]\n",
    "                column[:,4]=np.where(patch_place>0,1,0)\n",
    "                if not((patch_place==0).all()):\n",
    "                    column[0,3]=round(max(patch_place),1)\n",
    "                    column[:,5]=np.where(patch_place==max(patch_place),1,0)\n",
    "\n",
    "        #Column 6 equals Species\n",
    "        if list_data[i] in species.keys() and species[list_data[i]] in SPEC.keys():\n",
    "            column[0,6+SPEC[species[list_data[i]]]]=1\n",
    "\n",
    "        # Columns 17 equals expression\n",
    "        if list_data[i] in expression.keys() and not(np.isnan(expression[list_data[i]])):\n",
    "            expression_value=round(expression[list_data[i]],1)  \n",
    "            column[0,16]=expression_value\n",
    "            rk=0\n",
    "            for k in EXP[1:]:\n",
    "                if expression_value>=k:\n",
    "                    rk+=1\n",
    "            column[0,17+rk]=1    \n",
    "        padding_zero = np.zeros((len(data[i]),2))  \n",
    "        column = np.c_[column,padding_zero]\n",
    "        new_data[i]=np.c_[data[i],column]        \n",
    "\n",
    "    if agg_data is not None:   \n",
    "        agg=np.zeros((len(agg_data),len(data[0]),97))\n",
    "        for j in tqdm(range(len(agg_data))):\n",
    "            # one hot encode sequences\n",
    "            agg[j, :len(agg_data.iloc[j]['Sequence']), :20] = np.eye(20)[[AA.index(aa) for aa in list(agg_data.iloc[j]['Sequence'])]]\n",
    "            # add a label\n",
    "            agg[j, 0, -2+AGG[agg_data.iloc[j]['Classification']]]=1\n",
    "        new_data = np.concatenate((new_data, agg))\n",
    "    \n",
    "    print(new_data.shape, 'final')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da19142-865b-4123-a7d9-ab37c914fd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 1632, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10848/10848 [00:48<00:00, 222.29it/s]\n",
      "100%|██████████| 1122/1122 [00:00<00:00, 5414.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11970, 1632, 97) final\n",
      "(21, 1494, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 204.18it/s]\n",
      "100%|██████████| 277/277 [00:00<00:00, 5704.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 1494, 97) final\n",
      "(513, 874, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 513/513 [00:01<00:00, 285.39it/s]\n",
      "100%|██████████| 277/277 [00:00<00:00, 5838.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790, 874, 97) final\n",
      "(115, 1111, 97) initial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 282.55it/s]\n",
      "100%|██████████| 277/277 [00:00<00:00, 5747.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 1111, 97) final\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    name_train,name_casp,name_cb,name_ts=np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/Train_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CASP12_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CB513_HHblits.npz\")['pdbids'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/TS115_HHblits.npz\")['pdbids']\n",
    "    data_train,data_casp,data_cb,data_ts=np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/Train_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CASP12_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/CB513_HHblits.npz\")['data'],np.load(r\"/Users/deagogishvili/Documents/PhD/multitask/data/source_dataset/TS115_HHblits.npz\")['data']\n",
    "    list_train, list_casp,list_cb,list_ts=get_ASA(data_train,name_train,aggregation_train),get_ASA(data_casp,name_casp,aggregation_test),get_ASA(data_cb,name_cb,aggregation_test),get_ASA(data_ts,name_ts,aggregation_test)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Train_HHblits_extended.npz',pdbids=name_train,data=list_train)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CASP12_HHblits_extended.npz',pdbids=name_casp,data=list_casp)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/CB513_HHblits_extended.npz',pdbids=name_cb,data=list_cb)\n",
    "    np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/TS115_HHblits_extended.npz',pdbids=name_ts,data=list_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8d6236-614c-4755-b826-3b7d8c4b7298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 1632, 68)\n",
      "(21, 1494, 68)\n",
      "(513, 874, 68)\n",
      "(115, 1111, 68)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_casp.shape)\n",
    "print(data_cb.shape)\n",
    "print(data_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6096e2-8111-4420-8127-719ea417cbcd",
   "metadata": {},
   "source": [
    "# Creating separate train/test sets for Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f70c32c1-5c77-4854-8f7c-db023e332e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Dimensions: (392, 1111, 97)\n",
      "Subset Dimensions: (277, 1111, 97)\n"
     ]
    }
   ],
   "source": [
    "# Load the extended dataset\n",
    "extended_data = np.load('/Users/deagogishvili/Documents/PhD/multitask/data/extended/TS115_HHblits_extended.npz')\n",
    "\n",
    "# Extract data and pdbids\n",
    "data = extended_data['data']\n",
    "pdbids = extended_data['pdbids']\n",
    "\n",
    "# Print the dimensions of the original dataset\n",
    "print(\"Original Dataset Dimensions:\", data.shape)\n",
    "\n",
    "# Take only the last 1122 rows added\n",
    "new_data = data[-277:]\n",
    "new_pdbids = pdbids[-277:]\n",
    "\n",
    "# Print the dimensions of the subset\n",
    "print(\"Subset Dimensions:\", new_data.shape)\n",
    "\n",
    "# Save the new dataset\n",
    "np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Test_agg.npz', pdbids=new_pdbids, data=new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5170fd-be23-4834-9ce7-5771bbf86aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Dimensions: (11970, 1632, 97)\n",
      "Subset Dimensions: (1122, 1632, 97)\n"
     ]
    }
   ],
   "source": [
    "# Load the extended dataset\n",
    "extended_data = np.load('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Train_HHblits_extended.npz')\n",
    "\n",
    "# Extract data and pdbids\n",
    "data = extended_data['data']\n",
    "pdbids = extended_data['pdbids']\n",
    "\n",
    "# Print the dimensions of the original dataset\n",
    "print(\"Original Dataset Dimensions:\", data.shape)\n",
    "\n",
    "# Take only the last 1122 rows added\n",
    "new_data = data[-1122:]\n",
    "new_pdbids = pdbids[-1122:]\n",
    "\n",
    "# Print the dimensions of the subset\n",
    "print(\"Subset Dimensions:\", new_data.shape)\n",
    "\n",
    "# Save the new dataset\n",
    "np.savez_compressed('/Users/deagogishvili/Documents/PhD/multitask/data/extended/Train_HHblits_extended_agg.npz', pdbids=new_pdbids, data=new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
