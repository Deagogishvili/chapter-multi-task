{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736023fb-a2d5-4421-92f0-7b512839c782",
   "metadata": {},
   "source": [
    "# Introduction to the CASP14 Data Download Notebook\n",
    "\n",
    "## Overview\n",
    "\n",
    "This IPython notebook is designed to automate the process of downloading and organizing Alphafold2 data from the CASP14. It focuses on fetching sequences, target structures, and predictions.\n",
    "\n",
    "## Contents of the Notebook\n",
    "\n",
    "1. **Utility Functions:**\n",
    "   - `get_tar_gz_links(url)`: Fetches `.tar.gz` file links to targets from a specified URL.\n",
    "   - `download_predictions(url, save_dir)`: Downloads and extracts alphafold2 model 1 pdb prediction.\n",
    "   - `download_targets(url, save_dir)`: Downloads and extracts target files.\n",
    "   - `download_sequences(url, save_dir)`: Downloads sequence data.\n",
    "\n",
    "2. **Main Function:**\n",
    "   - Coordinates the entire downloading and organizing process.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Specify Save Directory:** Set the `save_dir` variable to the desired path on your system where you want the data to be saved.\n",
    "2. **Run the Notebook:** Execute the cells in the notebook sequentially.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Ensure you have a stable internet connection for uninterrupted downloading.\n",
    "- The necessary Python libraries (`os`, `shutil`, `tempfile`, `tarfile`, `requests`, `BeautifulSoup`, `tqdm`) should be installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36ca8130-5169-4a81-abe5-f2143c3c6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import tarfile\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_tar_gz_links(url):\n",
    "    \"\"\"\n",
    "    Get links for .tar.gz files from the given URL.\n",
    "\n",
    "    Args:\n",
    "    - url (str): The URL containing the .tar.gz files to be downloaded.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of URLs for the .tar.gz files.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    links = soup.find_all('a', href=lambda href: href and href.endswith('.tar.gz'))\n",
    "    \n",
    "    return [urljoin(url, link['href']) for link in links]\n",
    "\n",
    "def download_predictions(url, save_dir):\n",
    "    \"\"\"\n",
    "    Download predictions from the provided list of links.\n",
    "\n",
    "    Args:\n",
    "    - links (list): A list of URLs for the .tar.gz files to be downloaded.\n",
    "    - save_dir (str): The directory where the downloaded files with 'TS427' in the name will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    links = get_tar_gz_links(url)\n",
    "    \n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    for link in tqdm(links, desc=\"Downloading\", unit=\"file\"):\n",
    "        target = os.path.basename(link)[:-7]\n",
    "        if os.path.exists(os.path.join(save_dir, target + '.pdb')):\n",
    "            continue\n",
    "        file_name = os.path.join(tmp_dir, os.path.basename(link))\n",
    "        with open(file_name, 'wb') as f:\n",
    "            response = requests.get(link)\n",
    "            f.write(response.content)\n",
    "\n",
    "        tar = tarfile.open(file_name, 'r:gz')\n",
    "        for member in tar.getmembers():\n",
    "            if 'TS427_1' in member.name:\n",
    "                file_content = tar.extractfile(member).read()\n",
    "                with open(os.path.join(save_dir, target + '.pdb'), 'wb') as f:\n",
    "                    f.write(file_content)\n",
    "                break\n",
    "        tar.close()\n",
    "        \n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "def download_targets(url, save_dir):\n",
    "    \"\"\"\n",
    "    Download a .tgz file from the given URL, extract its contents to a specified directory, and remove the .tgz file.\n",
    "\n",
    "    Args:\n",
    "    - url (str): The URL of the .tgz file to be downloaded.\n",
    "    - save_dir (str): The directory where the extracted files will be saved.\n",
    "    \"\"\"\n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    file_name = os.path.join(tmp_dir, os.path.basename(url))\n",
    "    with open(file_name, 'wb') as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "\n",
    "    with tarfile.open(file_name, 'r:gz') as tar:\n",
    "        tar.extractall(path=save_dir)\n",
    "    \n",
    "    print(\"Downloaded targets\")\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "def download_sequences(url, save_dir):\n",
    "    \"\"\"\n",
    "    Download sequences from the given URL and save them as a FASTA file in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - url (str): The URL of the sequences file to be downloaded.\n",
    "    - save_dir (str): The directory where the sequences will be saved as a FASTA file.\n",
    "    \"\"\"\n",
    "    file_name = os.path.join(save_dir, 'sequences.fasta')\n",
    "    with open(file_name, 'wb') as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "    print(\"Downloaded sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97c8f3f3-b518-4d4d-827e-c98c67775d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(save_dir):\n",
    "    \"\"\"\n",
    "    Main function to download .tar.gz files from the given URL to the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - save_dir (str): The directory where the downloaded files with 'TS427' in the name will be saved.\n",
    "    \"\"\"\n",
    "    save_dir_sequences = os.path.join(save_dir, \"sequences\")\n",
    "    if not os.path.exists(save_dir_sequences):\n",
    "        os.makedirs(save_dir_sequences)\n",
    "        \n",
    "    url_sequences = \"https://predictioncenter.org/download_area/CASP14/sequences/casp14.seq.txt\"\n",
    "    download_sequences(url_sequences, save_dir_sequences)\n",
    "    \n",
    "    save_dir_targets = os.path.join(save_dir, \"targets\")\n",
    "    if not os.path.exists(save_dir_targets):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    url_targets = \"https://predictioncenter.org/download_area/CASP14/targets/_4invitees/casp14.targ.whole.4invitees.tgz\"\n",
    "    download_targets(url_targets, save_dir_targets)\n",
    "\n",
    "    save_dir_predictions = os.path.join(save_dir, \"predictions\")\n",
    "    if not os.path.exists(save_dir_targets):\n",
    "        os.makedirs(save_dir_targets)\n",
    "        \n",
    "    url_predictions = \"https://predictioncenter.org/download_area/CASP14/predictions/regular/\"\n",
    "    download_predictions(url_predictions, save_dir_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0f6a3fbb-0d24-4235-a5a8-607c77f1d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded sequences\n",
      "Downloaded targets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 84/84 [00:50<00:00,  1.66file/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"../data/casp14_alphafold\"\n",
    "main(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
