{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb92f08-5be0-4688-a620-f977ce6d8ca7",
   "metadata": {},
   "source": [
    "# AlphaFold extract average prediction confidence\n",
    "\n",
    "## Overview\n",
    "This function handles the downloading, unpacking, and processing of predicted AlphaFold structures from the EBI database (https://ftp.ebi.ac.uk/pub/databases/alphafold/). The primary goal of this function is to calculate average confidence scores for each protein structure in the dataset.\n",
    "\n",
    "## Functionality\n",
    "- **Download and Unpack**: If the AlphaFold data (specified by the URL) is not already present in the specified download directory, the function will download and unpack it.\n",
    "- **Data Processing**: For each protein structure file, the function calculates the average confidence score. \n",
    "- **Output Generation**: It then generates a CSV file containing these scores along with other relevant information about each protein.\n",
    "\n",
    "## Parameters\n",
    "1. `url`: The URL where the predicted AlphaFold structures are located. This URL should point to a tar file containing the predicted structures.\n",
    "2. `output_file` (optional): The path to the output CSV file. Default is `\"./output.csv\"`.\n",
    "3. `download_path` (optional): The base path where the data will be downloaded and unpacked. Default is the current directory (`\"./\"`).\n",
    "\n",
    "## Output\n",
    "The function outputs a CSV file with the following columns:\n",
    "- `protein_id`: The identifier of the protein.\n",
    "- `f_value`: Additional identifier related to the protein.\n",
    "- `model`: The model version used in the prediction.\n",
    "- `avg_confidence`: The average confidence score for the predicted structure.\n",
    "\n",
    "### Example Output\n",
    "| protein_id   | f_value | model   | avg_confidence |\n",
    "|--------------|---------|---------|----------------|\n",
    "| A0A024R1R8   | F1      | model_v4| 72.2203125     |\n",
    "\n",
    "## Usage Notes\n",
    "- Ensure the URL provided points directly to a tar file containing the AlphaFold data.\n",
    "- The function requires internet access to download the data.\n",
    "- Adequate disk space should be available for downloading and unpacking the data.\n",
    "- The function depends on external libraries such as `os`, `pandas`, and `tqdm` for its operations.\n",
    "\n",
    "## Example Usage\n",
    "```python\n",
    "main(url=\"https://ftp.ebi.ac.uk/pub/databases/alphafold/v4/UP000005640_9606_HUMAN_v4.tar\", \n",
    "     output_file=\"./output.csv\", \n",
    "     download_path=\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882dea13-0f56-4419-b29e-046d3ddd0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f379ac-21dd-4480-b8e5-bc96fbe1be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_path):\n",
    "    \"\"\"\n",
    "    Downloads a file from the given URL to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - url: URL of the file to download.\n",
    "    - save_path: Path where the file should be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    response = requests.head(url)\n",
    "    file_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "    with requests.get(url, stream=True) as r, open(save_path, 'wb') as f:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=1024), total=file_size//1024, unit='KB', desc=os.path.basename(save_path)):\n",
    "            if chunk:\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93301af-6d38-4dfc-8c1a-2921c9a1073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_tar(tar_file, extract_path):\n",
    "    \"\"\"\n",
    "    Extracts a .tar file to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - tar_file: Path to the .tar file.\n",
    "    - extract_path: Path where the contents of the .tar file should be extracted.\n",
    "    \"\"\"\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_file, 'r') as tar:\n",
    "        members = tar.getmembers()\n",
    "        for member in tqdm(members, desc=os.path.basename(tar_file), unit='file'):\n",
    "            tar.extract(member, extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e757709c-fafc-4eb7-84a7-1618b1242f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_confidence(pdb_file):\n",
    "    \"\"\"\n",
    "    Extracts the average confidence of all residues in a PDB file.\n",
    "\n",
    "    Args:\n",
    "    - pdb_file: Path to the gzipped PDB file.\n",
    "\n",
    "    Returns:\n",
    "    - avg_confidence_score: Average confidence score of all residues.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(pdb_file, 'rt') as f:\n",
    "            parser = PDBParser()\n",
    "            structure = parser.get_structure(os.path.splitext(pdb_file)[0], f)\n",
    "            confidence_scores = []\n",
    "    \n",
    "            for chain in structure[0]:\n",
    "                for residue in chain:\n",
    "                    confidence_scores.append(residue[\"CA\"].get_bfactor())\n",
    "    \n",
    "        if confidence_scores:\n",
    "            return sum(confidence_scores) / len(confidence_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"unable to process {pdb_file}. Got error: {e}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d8df90-6a65-4757-983a-6105cad96d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url, output_file = \"../data/alphafold/output.csv\", download_path = \"../data/alphafold/download\"):\n",
    "    \"\"\"\n",
    "    Sets up the AlphaFold avg confidence data, downloading and unpacking if necessary.\n",
    "\n",
    "    Args:\n",
    "    - url: Alphafold predicted proteome URL location.\n",
    "    - output_file: Path for the output file.\n",
    "    - download_path: Path to the download folder.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(url) \n",
    "    tar_file = f\"{download_path}/{filename}\"\n",
    "    data_folder = f\"{download_path}/{os.path.splitext(filename)[0]}\"\n",
    "\n",
    "    if not os.path.exists(tar_file):\n",
    "        print(\"Downloading data...\")\n",
    "        download_file(url, tar_file)\n",
    "        print(\"Download complete.\")\n",
    "\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(\"Unpacking data...\")\n",
    "        unpack_tar(tar_file, data_folder)\n",
    "        print(\"Unpacking complete.\")\n",
    "\n",
    "    pdb_files = [f for f in os.listdir(data_folder) if f.endswith(\".pdb.gz\")]\n",
    "    data = []\n",
    "    for pdb_file in tqdm(pdb_files, desc=\"Processing files\", unit=\"file\"):\n",
    "        avg_confidence = get_avg_confidence(os.path.join(data_folder, pdb_file))\n",
    "        if avg_confidence is not None:\n",
    "            no_extension = pdb_file.split('.')[0]\n",
    "            splits = no_extension.split(\"-\")[1:]\n",
    "            data.append(splits + [avg_confidence])\n",
    "    columns = ['protein_id', 'f_value', 'model', 'avg_confidence']\n",
    "    pd.DataFrame(data, columns=columns).to_csv(f\"{output_file}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e188df78-a60f-43b4-bcfb-9b069d3e85e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 23391/23391 [42:47<00:00,  9.11file/s] \n"
     ]
    }
   ],
   "source": [
    "url = \"https://ftp.ebi.ac.uk/pub/databases/alphafold/v4/UP000005640_9606_HUMAN_v4.tar\"\n",
    "main(url, output_file = \"../data/alphafold/output.csv\", download_path = \"../data/alphafold/download\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
