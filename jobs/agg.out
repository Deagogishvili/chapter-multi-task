Requirement already satisfied: click in /scistor/informatica/dgi460/anaconda3/envs/dl2022/lib/python3.10/site-packages (8.1.3)
Requirement already satisfied: fair-esm in /scistor/informatica/dgi460/anaconda3/envs/dl2022/lib/python3.10/site-packages (2.0.0)
Processing /scistor/informatica/dgi460/PROT/PROT
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Building wheels for collected packages: PROT
  Building wheel for PROT (setup.py): started
  Building wheel for PROT (setup.py): finished with status 'done'
  Created wheel for PROT: filename=PROT-0.0.1-py3-none-any.whl size=95580 sha256=8236f8fb0ae8ed40b94bae95f67778e681efc4372ba7e50da366aee316096011
  Stored in directory: /scratch/670984/pip-ephem-wheel-cache-tnyoeh8m/wheels/f3/f3/d5/e95d019bbe728e863c8658a0c362e103b5264b28afecea62b9
Successfully built PROT
Installing collected packages: PROT
  Attempting uninstall: PROT
    Found existing installation: PROT 0.0.1
    Uninstalling PROT-0.0.1:
      Successfully uninstalled PROT-0.0.1
Successfully installed PROT-0.0.1
2024-02-08 15:41:02,217 - PROT.PROT.main - INFO - Building: PROT.models.ESM2_original_extended
FINETUNING CHOSEN: LoRA
Gradient Checkpointing 2
2024-02-08 15:41:08,111 - PROT.PROT.models.ESM2_original_extended.model - INFO - <init>: 
ESM2_original_extended(
  (embedding): ESM2Embedding(
    (model): ESM2(
      (embed_tokens): Embedding(33, 1280, padding_idx=1)
      (layers): ModuleList(
        (0): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (8): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (9): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (10): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (11): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (12): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (13): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (14): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (15): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (16): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (17): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (18): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (19): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (20): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (21): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (22): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (23): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (24): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (25): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (26): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (27): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (28): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (29): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (30): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (31): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (32): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (contact_head): ContactPredictionHead(
        (regression): Linear(in_features=660, out_features=1, bias=True)
        (activation): Sigmoid()
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (lm_head): RobertaLMHead(
        (dense): Linear(in_features=1280, out_features=1280, bias=True)
        (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (conv): ModuleList(
    (0): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Conv1d(1280, 32, kernel_size=(129,), stride=(1,), padding=(64,))
      (2): ReLU()
    )
    (1): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Conv1d(1280, 32, kernel_size=(257,), stride=(1,), padding=(128,))
      (2): ReLU()
    )
  )
  (batch_norm): BatchNorm1d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lstm): LSTM(1344, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)
  (lstm_dropout_layer): Dropout(p=0.5, inplace=False)
  (ss8): Sequential(
    (0): Linear(in_features=2048, out_features=8, bias=True)
  )
  (ss3): Sequential(
    (0): Linear(in_features=2048, out_features=3, bias=True)
  )
  (disorder): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (rsa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
    (1): Sigmoid()
  )
  (phi): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
    (1): Tanh()
  )
  (psi): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
    (1): Tanh()
  )
  (tasa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (thsa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (lhp): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (hp_loc): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (lhp_loc): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (species): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
  (expression): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (aggregation): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
)
Trainable parameters: 61504231
2024-02-08 15:41:08,122 - PROT.PROT.main - INFO - Using devices [0] of available devices [0]
Using devices [0] of available devices [0]
2024-02-08 15:41:09,385 - PROT.PROT.main - INFO - Building: torch.optim.Adam
2024-02-08 15:41:09,387 - PROT.PROT.main - INFO - Building: PROT.data_loader.augmentation.sparse_token
FINETUNING CHOSEN: no finetuning
Gradient Checkpointing None
2024-02-08 15:41:10,716 - PROT.PROT.main - INFO - Building: PROT.data_loader.data_loaders.NSPDataLoader
2024-02-08 15:41:10,961 - PROT.PROT.main - INFO - Getting loss and metric function handles
2024-02-08 15:41:10,962 - PROT.PROT.main - INFO - Initialising trainer
GRADIENT ACCUMULATION 6
2024-02-08 15:41:10,974 - PROT.PROT.base.base_trainer - INFO - Starting training...
Multi Task Loss
SS8 : 1 // SS3: 5 // DIS: 5 // RSA: 100 // PHI: 5 // PSI: 5 // TASA: 1e-07 // THSA: 2e-06 // LHP: 5e-06 // HP LOC: 5 // LHP LOC: 5 // SPECIES: 0.04 // EXPRESSION: 0.06 // AGGREGATION: 0.06
2024-02-08 15:41:12,691 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [0/1068 (0%)] Loss: 25.839575
2024-02-08 15:42:08,031 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [900/1068 (84%)] Loss: 3.952241
2024-02-08 15:42:20,660 - PROT.PROT.base.base_trainer - INFO - epoch          : 0
2024-02-08 15:42:20,661 - PROT.PROT.base.base_trainer - INFO - loss           : 5.954697687451432
2024-02-08 15:42:20,662 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.5555555559694767
2024-02-08 15:42:20,663 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.5833333358168602
2024-02-08 15:42:20,664 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:42:20,665 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:42:20,666 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:42:20,667 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:42:20,668 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 58.20248889923096
2024-02-08 15:42:20,669 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 56.85050702095032
2024-02-08 15:42:20,670 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:42:20,671 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:42:20,672 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:42:20,673 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:42:20,674 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:42:20,675 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:42:20,676 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:42:20,677 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:42:20,678 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:42:20,679 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.5000000149011612
2024-02-08 15:42:20,680 - PROT.PROT.base.base_trainer - INFO - val_loss       : 3.527835249900818
2024-02-08 15:42:20,681 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:42:20,682 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:42:20,683 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:42:20,684 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:42:20,685 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:42:20,686 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:42:20,687 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 1.591899390731539
2024-02-08 15:42:20,688 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 3.3450880220958163
2024-02-08 15:42:20,689 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:42:20,690 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:42:20,691 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:42:20,692 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:42:20,693 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:42:20,694 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:42:20,695 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:42:20,696 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:42:20,697 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:42:20,698 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7500000101115022
2024-02-08 15:42:41,217 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch0.pth ...
2024-02-08 15:43:14,859 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:43:16,656 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [0/1068 (0%)] Loss: 3.659610
2024-02-08 15:44:12,000 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [900/1068 (84%)] Loss: 2.671963
2024-02-08 15:44:24,107 - PROT.PROT.base.base_trainer - INFO - epoch          : 1
2024-02-08 15:44:24,108 - PROT.PROT.base.base_trainer - INFO - loss           : 2.855850628236445
2024-02-08 15:44:24,109 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:44:24,110 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:44:24,112 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:44:24,113 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:44:24,114 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:44:24,115 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:44:24,116 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 5.576038837432861
2024-02-08 15:44:24,117 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 5.993051290512085
2024-02-08 15:44:24,118 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:44:24,119 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:44:24,121 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:44:24,122 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:44:24,123 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:44:24,124 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:44:24,125 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:44:24,126 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:44:24,127 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:44:24,128 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.5000000149011612
2024-02-08 15:44:24,129 - PROT.PROT.base.base_trainer - INFO - val_loss       : 2.0643531531095505
2024-02-08 15:44:24,130 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:44:24,131 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:44:24,132 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:44:24,132 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:44:24,134 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:44:24,135 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:44:24,136 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 1.0822636069996017
2024-02-08 15:44:24,137 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 1.0651706882885523
2024-02-08 15:44:24,138 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:44:24,139 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:44:24,140 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:44:24,141 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:44:24,142 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:44:24,143 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:44:24,144 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:44:24,145 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:44:24,146 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:44:24,147 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7142857233328479
2024-02-08 15:44:43,068 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch1.pth ...
2024-02-08 15:45:11,618 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:45:13,600 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [0/1068 (0%)] Loss: 2.092733
2024-02-08 15:46:08,817 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [900/1068 (84%)] Loss: 1.454521
2024-02-08 15:46:20,680 - PROT.PROT.base.base_trainer - INFO - epoch          : 2
2024-02-08 15:46:20,681 - PROT.PROT.base.base_trainer - INFO - loss           : 1.7482228672750448
2024-02-08 15:46:20,682 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:46:20,683 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:46:20,685 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:46:20,686 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:46:20,687 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:46:20,688 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:46:20,689 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 3.6572787761688232
2024-02-08 15:46:20,690 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 3.6967471837997437
2024-02-08 15:46:20,691 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:46:20,692 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:46:20,693 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:46:20,695 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:46:20,696 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:46:20,697 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:46:20,698 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:46:20,699 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:46:20,700 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:46:20,701 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 1.0
2024-02-08 15:46:20,702 - PROT.PROT.base.base_trainer - INFO - val_loss       : 1.3291453484977995
2024-02-08 15:46:20,703 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:46:20,704 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:46:20,705 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:46:20,706 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:46:20,707 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:46:20,708 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:46:20,710 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 1.0493317448667117
2024-02-08 15:46:20,714 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 1.060029604605266
2024-02-08 15:46:20,717 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:46:20,718 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:46:20,719 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:46:20,720 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:46:20,721 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:46:20,722 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:46:20,724 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:46:20,725 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:46:20,726 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:46:20,727 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7142857217362949
2024-02-08 15:46:38,930 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch2.pth ...
2024-02-08 15:47:00,244 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:47:01,635 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [0/1068 (0%)] Loss: 1.235109
2024-02-08 15:47:56,542 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [900/1068 (84%)] Loss: 1.183754
2024-02-08 15:48:08,697 - PROT.PROT.base.base_trainer - INFO - epoch          : 3
2024-02-08 15:48:08,697 - PROT.PROT.base.base_trainer - INFO - loss           : 1.1536040727125993
2024-02-08 15:48:08,699 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:48:08,700 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:48:08,701 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:48:08,702 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:48:08,703 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:48:08,705 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:48:08,706 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 1.8125421404838562
2024-02-08 15:48:08,707 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 2.517920196056366
2024-02-08 15:48:08,707 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:48:08,708 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:48:08,709 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:48:08,710 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:48:08,711 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:48:08,712 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:48:08,713 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:48:08,714 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:48:08,715 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:48:08,716 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.6666666716337204
2024-02-08 15:48:08,717 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.9143536910414696
2024-02-08 15:48:08,718 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:48:08,719 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:48:08,720 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:48:08,721 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:48:08,722 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:48:08,723 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:48:08,724 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.7206599941211087
2024-02-08 15:48:08,725 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.4724323395639658
2024-02-08 15:48:08,726 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:48:08,727 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:48:08,728 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:48:08,729 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:48:08,730 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:48:08,730 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:48:08,731 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:48:08,732 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:48:08,733 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:48:08,734 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7678571566939354
2024-02-08 15:48:26,210 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch3.pth ...
2024-02-08 15:48:45,708 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:48:47,001 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [0/1068 (0%)] Loss: 0.836628
2024-02-08 15:49:42,217 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [900/1068 (84%)] Loss: 0.877544
2024-02-08 15:49:54,252 - PROT.PROT.base.base_trainer - INFO - epoch          : 4
2024-02-08 15:49:54,253 - PROT.PROT.base.base_trainer - INFO - loss           : 0.835728799368606
2024-02-08 15:49:54,255 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:49:54,256 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:49:54,257 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:49:54,258 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:49:54,260 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:49:54,261 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:49:54,262 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 1.7813056111335754
2024-02-08 15:49:54,264 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 1.6607567071914673
2024-02-08 15:49:54,265 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:49:54,266 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:49:54,267 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:49:54,268 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:49:54,270 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:49:54,271 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:49:54,272 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:49:54,273 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:49:54,274 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:49:54,275 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.6666666716337204
2024-02-08 15:49:54,276 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.6646501038755689
2024-02-08 15:49:54,277 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:49:54,278 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:49:54,279 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:49:54,280 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:49:54,281 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:49:54,282 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:49:54,283 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.3386315503822906
2024-02-08 15:49:54,284 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.3198223558387586
2024-02-08 15:49:54,285 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:49:54,286 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:49:54,287 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:49:54,288 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:49:54,289 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:49:54,290 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:49:54,291 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:49:54,292 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:49:54,293 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:49:54,294 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7500000101115022
2024-02-08 15:50:11,635 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch4.pth ...
2024-02-08 15:50:33,638 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:50:35,129 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [0/1068 (0%)] Loss: 0.675256
2024-02-08 15:51:30,134 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [900/1068 (84%)] Loss: 0.682626
2024-02-08 15:51:42,180 - PROT.PROT.base.base_trainer - INFO - epoch          : 5
2024-02-08 15:51:42,181 - PROT.PROT.base.base_trainer - INFO - loss           : 0.63006253912346
2024-02-08 15:51:42,182 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:51:42,183 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:51:42,184 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:51:42,185 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:51:42,186 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:51:42,188 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:51:42,189 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.919598251581192
2024-02-08 15:51:42,190 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 1.0587182641029358
2024-02-08 15:51:42,191 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:51:42,192 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:51:42,193 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:51:42,194 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:51:42,195 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:51:42,196 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:51:42,197 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:51:42,198 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:51:42,199 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:51:42,200 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.6666666865348816
2024-02-08 15:51:42,202 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.607474898653371
2024-02-08 15:51:42,203 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:51:42,204 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:51:42,205 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:51:42,206 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:51:42,207 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:51:42,207 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:51:42,208 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.3590424337557384
2024-02-08 15:51:42,209 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.49551027002079145
2024-02-08 15:51:42,211 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:51:42,212 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:51:42,213 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:51:42,214 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:51:42,215 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:51:42,216 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:51:42,217 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:51:42,218 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:51:42,219 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:51:42,220 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.6964285815400737
2024-02-08 15:52:02,310 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch5.pth ...
2024-02-08 15:52:23,164 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:52:24,612 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [0/1068 (0%)] Loss: 0.710289
2024-02-08 15:53:19,852 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [900/1068 (84%)] Loss: 0.342329
2024-02-08 15:53:31,822 - PROT.PROT.base.base_trainer - INFO - epoch          : 6
2024-02-08 15:53:31,822 - PROT.PROT.base.base_trainer - INFO - loss           : 0.5051988707418513
2024-02-08 15:53:31,824 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:53:31,825 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:53:31,827 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:53:31,828 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:53:31,829 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:53:31,830 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:53:31,832 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.7548384666442871
2024-02-08 15:53:31,834 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.7639810144901276
2024-02-08 15:53:31,835 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:53:31,836 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:53:31,838 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:53:31,839 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:53:31,840 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:53:31,842 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:53:31,843 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:53:31,844 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:53:31,845 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:53:31,846 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.8333333432674408
2024-02-08 15:53:31,847 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.5002119173961026
2024-02-08 15:53:31,849 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:53:31,850 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:53:31,851 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:53:31,852 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:53:31,853 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:53:31,855 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:53:31,856 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.20414067405675138
2024-02-08 15:53:31,857 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.1490008333431823
2024-02-08 15:53:31,859 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:53:31,860 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:53:31,861 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:53:31,863 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:53:31,865 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:53:31,866 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:53:31,868 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:53:31,869 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:53:31,870 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:53:31,872 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7678571519042764
2024-02-08 15:53:49,845 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch6.pth ...
2024-02-08 15:54:09,989 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:54:11,353 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [0/1068 (0%)] Loss: 0.360078
2024-02-08 15:55:06,324 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [900/1068 (84%)] Loss: 0.437436
2024-02-08 15:55:18,472 - PROT.PROT.base.base_trainer - INFO - epoch          : 7
2024-02-08 15:55:18,473 - PROT.PROT.base.base_trainer - INFO - loss           : 0.46204647810441246
2024-02-08 15:55:18,474 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:55:18,475 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:55:18,477 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:55:18,478 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:55:18,479 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:55:18,480 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:55:18,481 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.43318338692188263
2024-02-08 15:55:18,483 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.5374268442392349
2024-02-08 15:55:18,484 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:55:18,485 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:55:18,486 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:55:18,487 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:55:18,488 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:55:18,489 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:55:18,490 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:55:18,491 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:55:18,492 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:55:18,493 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.8333333432674408
2024-02-08 15:55:18,494 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.49170065617987085
2024-02-08 15:55:18,495 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:55:18,497 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:55:18,498 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:55:18,499 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:55:18,500 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:55:18,501 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:55:18,502 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.16352641955018044
2024-02-08 15:55:18,503 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.30401785352400373
2024-02-08 15:55:18,504 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:55:18,505 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:55:18,506 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:55:18,506 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:55:18,508 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:55:18,509 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:55:18,510 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:55:18,511 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:55:18,512 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:55:18,513 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7678571508399078
2024-02-08 15:55:37,673 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch7.pth ...
2024-02-08 15:55:58,081 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:55:59,403 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [0/1068 (0%)] Loss: 0.370354
2024-02-08 15:56:54,701 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [900/1068 (84%)] Loss: 0.519365
2024-02-08 15:57:06,864 - PROT.PROT.base.base_trainer - INFO - epoch          : 8
2024-02-08 15:57:06,865 - PROT.PROT.base.base_trainer - INFO - loss           : 0.41835803809745226
2024-02-08 15:57:06,866 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:57:06,867 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:57:06,868 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:57:06,869 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:57:06,871 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:57:06,872 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:57:06,873 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.272547647356987
2024-02-08 15:57:06,874 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.3830602914094925
2024-02-08 15:57:06,875 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:57:06,876 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:57:06,877 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:57:06,878 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:57:06,879 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:57:06,880 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:57:06,881 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:57:06,882 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:57:06,884 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:57:06,885 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.8333333432674408
2024-02-08 15:57:06,886 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.47937445821506636
2024-02-08 15:57:06,887 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:57:06,888 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:57:06,889 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:57:06,890 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:57:06,891 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:57:06,892 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:57:06,893 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.173073020364557
2024-02-08 15:57:06,894 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.09916378876992635
2024-02-08 15:57:06,895 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:57:06,896 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:57:06,897 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:57:06,898 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:57:06,899 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:57:06,900 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:57:06,901 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:57:06,902 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:57:06,903 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:57:06,904 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7500000085149493
2024-02-08 15:57:27,195 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch8.pth ...
2024-02-08 15:57:45,525 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/ESM2/0208-154110/checkpoints/model_best.pth
2024-02-08 15:57:46,725 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [0/1068 (0%)] Loss: 0.515710
2024-02-08 15:58:41,858 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [900/1068 (84%)] Loss: 0.481699
2024-02-08 15:58:53,975 - PROT.PROT.base.base_trainer - INFO - epoch          : 9
2024-02-08 15:58:53,975 - PROT.PROT.base.base_trainer - INFO - loss           : 0.4051732952806113
2024-02-08 15:58:53,978 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 15:58:53,979 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 15:58:53,980 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 15:58:53,981 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 15:58:53,983 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 15:58:53,984 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 15:58:53,986 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.2978574186563492
2024-02-08 15:58:53,987 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.24109583348035812
2024-02-08 15:58:53,989 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 15:58:53,990 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 15:58:53,991 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 15:58:53,993 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 15:58:53,994 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 15:58:53,995 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 15:58:53,997 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 15:58:53,998 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 15:58:53,999 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 15:58:54,001 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.6666666865348816
2024-02-08 15:58:54,002 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.5600927195378712
2024-02-08 15:58:54,003 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 15:58:54,005 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 15:58:54,006 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 15:58:54,006 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 15:58:54,008 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 15:58:54,009 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 15:58:54,010 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.07521853941891875
2024-02-08 15:58:54,011 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.12513543159833976
2024-02-08 15:58:54,012 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 15:58:54,014 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 15:58:54,014 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 15:58:54,016 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 15:58:54,017 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 15:58:54,018 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 15:58:54,020 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 15:58:54,021 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 15:58:54,022 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 15:58:54,023 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.6785714376185622
2024-02-08 15:59:11,362 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch9.pth ...
2024-02-08 15:59:12,628 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [0/1068 (0%)] Loss: 0.297482
2024-02-08 16:00:07,700 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [900/1068 (84%)] Loss: 0.508779
2024-02-08 16:00:19,785 - PROT.PROT.base.base_trainer - INFO - epoch          : 10
2024-02-08 16:00:19,786 - PROT.PROT.base.base_trainer - INFO - loss           : 0.3854941852796145
2024-02-08 16:00:19,787 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 16:00:19,788 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 16:00:19,790 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 16:00:19,791 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 16:00:19,792 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 16:00:19,793 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 16:00:19,794 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.23983170092105865
2024-02-08 16:00:19,795 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.24016862362623215
2024-02-08 16:00:19,796 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 16:00:19,797 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 16:00:19,798 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 16:00:19,799 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 16:00:19,800 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 16:00:19,801 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 16:00:19,802 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 16:00:19,803 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 16:00:19,805 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 16:00:19,806 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.8333333432674408
2024-02-08 16:00:19,807 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.5802262553146907
2024-02-08 16:00:19,808 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 16:00:19,809 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 16:00:19,810 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 16:00:19,811 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 16:00:19,812 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 16:00:19,813 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 16:00:19,815 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.07856884133070707
2024-02-08 16:00:19,816 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.04026767994011087
2024-02-08 16:00:19,817 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 16:00:19,818 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 16:00:19,819 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 16:00:19,820 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 16:00:19,821 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 16:00:19,823 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 16:00:19,824 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 16:00:19,825 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 16:00:19,826 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 16:00:19,827 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.6607143016798156
2024-02-08 16:00:37,980 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch10.pth ...
2024-02-08 16:00:39,212 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [0/1068 (0%)] Loss: 0.418976
2024-02-08 16:01:34,177 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [900/1068 (84%)] Loss: 0.775128
2024-02-08 16:01:46,128 - PROT.PROT.base.base_trainer - INFO - epoch          : 11
2024-02-08 16:01:46,129 - PROT.PROT.base.base_trainer - INFO - loss           : 0.3708141128660143
2024-02-08 16:01:46,130 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 16:01:46,131 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 16:01:46,132 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 16:01:46,133 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 16:01:46,135 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 16:01:46,136 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 16:01:46,137 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.1754755675792694
2024-02-08 16:01:46,138 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.16187069565057755
2024-02-08 16:01:46,139 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 16:01:46,140 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 16:01:46,141 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 16:01:46,142 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 16:01:46,143 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 16:01:46,144 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 16:01:46,145 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 16:01:46,147 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 16:01:46,148 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 16:01:46,149 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.5000000149011612
2024-02-08 16:01:46,150 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.5071003554122788
2024-02-08 16:01:46,151 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 16:01:46,153 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 16:01:46,154 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 16:01:46,155 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 16:01:46,157 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 16:01:46,158 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 16:01:46,159 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.05512087998379554
2024-02-08 16:01:46,161 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.11047430748918227
2024-02-08 16:01:46,162 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 16:01:46,163 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 16:01:46,164 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 16:01:46,165 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 16:01:46,166 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 16:01:46,167 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 16:01:46,168 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 16:01:46,170 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 16:01:46,171 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 16:01:46,172 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7142857249294009
2024-02-08 16:02:03,707 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch11.pth ...
2024-02-08 16:02:04,892 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [0/1068 (0%)] Loss: 0.230087
2024-02-08 16:03:00,131 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [900/1068 (84%)] Loss: 0.553275
2024-02-08 16:03:12,080 - PROT.PROT.base.base_trainer - INFO - epoch          : 12
2024-02-08 16:03:12,081 - PROT.PROT.base.base_trainer - INFO - loss           : 0.3586008361982807
2024-02-08 16:03:12,082 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 16:03:12,084 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 16:03:12,085 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 16:03:12,086 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 16:03:12,087 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 16:03:12,089 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 16:03:12,090 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.11079162359237671
2024-02-08 16:03:12,091 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.1658572107553482
2024-02-08 16:03:12,092 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 16:03:12,093 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 16:03:12,094 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 16:03:12,095 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 16:03:12,096 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 16:03:12,098 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 16:03:12,099 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 16:03:12,100 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 16:03:12,101 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 16:03:12,102 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.8333333432674408
2024-02-08 16:03:12,103 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.4934024512767792
2024-02-08 16:03:12,104 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 16:03:12,105 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 16:03:12,106 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 16:03:12,107 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 16:03:12,108 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 16:03:12,109 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 16:03:12,110 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.06562662443944386
2024-02-08 16:03:12,111 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.0661221593618393
2024-02-08 16:03:12,113 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 16:03:12,114 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 16:03:12,115 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 16:03:12,116 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 16:03:12,117 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 16:03:12,118 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 16:03:12,119 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 16:03:12,120 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 16:03:12,121 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 16:03:12,122 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.7857142921004977
2024-02-08 16:03:29,959 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch12.pth ...
2024-02-08 16:03:31,183 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [0/1068 (0%)] Loss: 0.633777
2024-02-08 16:04:26,067 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [900/1068 (84%)] Loss: 0.488649
2024-02-08 16:04:37,975 - PROT.PROT.base.base_trainer - INFO - epoch          : 13
2024-02-08 16:04:37,975 - PROT.PROT.base.base_trainer - INFO - loss           : 0.3415056248431358
2024-02-08 16:04:37,977 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 16:04:37,978 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 16:04:37,979 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 16:04:37,980 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 16:04:37,982 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 16:04:37,983 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 16:04:37,984 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.10942820087075233
2024-02-08 16:04:37,985 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.10744959861040115
2024-02-08 16:04:37,986 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 16:04:37,987 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 16:04:37,988 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 16:04:37,989 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 16:04:37,990 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 16:04:37,991 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 16:04:37,992 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 16:04:37,993 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 16:04:37,994 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 16:04:37,995 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.6666666865348816
2024-02-08 16:04:37,996 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.638198251969048
2024-02-08 16:04:37,997 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 16:04:37,998 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 16:04:37,999 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 16:04:38,000 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 16:04:38,001 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 16:04:38,002 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 16:04:38,003 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.0729625175174858
2024-02-08 16:04:38,004 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.05874270473473838
2024-02-08 16:04:38,005 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 16:04:38,006 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 16:04:38,007 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 16:04:38,008 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 16:04:38,009 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 16:04:38,010 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 16:04:38,011 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 16:04:38,012 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 16:04:38,013 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 16:04:38,014 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.6250000127724239
2024-02-08 16:04:55,781 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch13.pth ...
2024-02-08 16:04:56,977 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [0/1068 (0%)] Loss: 0.423194
2024-02-08 16:05:52,176 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [900/1068 (84%)] Loss: 0.597068
2024-02-08 16:06:04,217 - PROT.PROT.base.base_trainer - INFO - epoch          : 14
2024-02-08 16:06:04,218 - PROT.PROT.base.base_trainer - INFO - loss           : 0.3355570123522188
2024-02-08 16:06:04,220 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 1.0
2024-02-08 16:06:04,221 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 1.0
2024-02-08 16:06:04,222 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0
2024-02-08 16:06:04,224 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0
2024-02-08 16:06:04,225 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0
2024-02-08 16:06:04,226 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0
2024-02-08 16:06:04,228 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 0.09850849583745003
2024-02-08 16:06:04,229 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 0.0733799934387207
2024-02-08 16:06:04,230 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 0.0
2024-02-08 16:06:04,232 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 0.0
2024-02-08 16:06:04,234 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 0.0
2024-02-08 16:06:04,235 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0
2024-02-08 16:06:04,237 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0
2024-02-08 16:06:04,238 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0
2024-02-08 16:06:04,239 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0
2024-02-08 16:06:04,241 - PROT.PROT.base.base_trainer - INFO - metric_species : 0
2024-02-08 16:06:04,242 - PROT.PROT.base.base_trainer - INFO - metric_expression: 0
2024-02-08 16:06:04,243 - PROT.PROT.base.base_trainer - INFO - metric_aggregation: 0.5000000149011612
2024-02-08 16:06:04,245 - PROT.PROT.base.base_trainer - INFO - val_loss       : 0.5922324825078249
2024-02-08 16:06:04,246 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 1.0
2024-02-08 16:06:04,247 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 1.0
2024-02-08 16:06:04,248 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0
2024-02-08 16:06:04,249 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0
2024-02-08 16:06:04,250 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0
2024-02-08 16:06:04,252 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0
2024-02-08 16:06:04,254 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 0.05152980976604989
2024-02-08 16:06:04,255 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 0.0758375223459942
2024-02-08 16:06:04,256 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 0.0
2024-02-08 16:06:04,257 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 0.0
2024-02-08 16:06:04,259 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 0.0
2024-02-08 16:06:04,260 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0
2024-02-08 16:06:04,261 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0
2024-02-08 16:06:04,263 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0
2024-02-08 16:06:04,265 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0
2024-02-08 16:06:04,266 - PROT.PROT.base.base_trainer - INFO - val_metric_species: 0
2024-02-08 16:06:04,267 - PROT.PROT.base.base_trainer - INFO - val_metric_expression: 0
2024-02-08 16:06:04,269 - PROT.PROT.base.base_trainer - INFO - val_metric_aggregation: 0.6428571550973824
2024-02-08 16:06:21,873 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/ESM2/0208-154110/checkpoints/checkpoint-epoch14.pth ...
2024-02-08 16:06:22,366 - PROT.PROT.main - INFO - Initialising evaluation
2024-02-08 16:06:23,908 - PROT.PROT.base.base_eval - INFO - Starting evaluating...
2024-02-08 16:06:29,726 - PROT.PROT.base.base_eval - INFO - metric_ss8: 1.0
2024-02-08 16:06:29,727 - PROT.PROT.base.base_eval - INFO - metric_ss3: 1.0
2024-02-08 16:06:29,728 - PROT.PROT.base.base_eval - INFO - metric_dis_mcc: 0.0
2024-02-08 16:06:29,730 - PROT.PROT.base.base_eval - INFO - metric_dis_fnr: 0.0
2024-02-08 16:06:29,731 - PROT.PROT.base.base_eval - INFO - metric_rsa: 0.0
2024-02-08 16:06:29,732 - PROT.PROT.base.base_eval - INFO - metric_asa: 0.0
2024-02-08 16:06:29,733 - PROT.PROT.base.base_eval - INFO - metric_phi: 0.17247213113931972
2024-02-08 16:06:29,734 - PROT.PROT.base.base_eval - INFO - metric_psi: 0.10245635979119622
2024-02-08 16:06:29,735 - PROT.PROT.base.base_eval - INFO - metric_tasa: 0.0
2024-02-08 16:06:29,736 - PROT.PROT.base.base_eval - INFO - metric_thsa: 0.0
2024-02-08 16:06:29,737 - PROT.PROT.base.base_eval - INFO - metric_lhp: 0.0
2024-02-08 16:06:29,738 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_mcc: 0.0
2024-02-08 16:06:29,739 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_fnr: 0.0
2024-02-08 16:06:29,740 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_mcc: 0.0
2024-02-08 16:06:29,741 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_fnr: 0.0
2024-02-08 16:06:29,742 - PROT.PROT.base.base_eval - INFO - metric_species: 0.0
2024-02-08 16:06:29,743 - PROT.PROT.base.base_eval - INFO - metric_expression: 0.0
2024-02-08 16:06:29,744 - PROT.PROT.base.base_eval - INFO - metric_aggregation: 0.7978339441631676
2024-02-08 16:06:29,746 - PROT.PROT.main - INFO - Finished!
done
