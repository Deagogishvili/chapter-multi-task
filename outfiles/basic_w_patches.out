Requirement already satisfied: click in /scistor/informatica/dgi460/anaconda3/envs/dl2022/lib/python3.10/site-packages (8.1.3)
Requirement already satisfied: fair-esm in /scistor/informatica/dgi460/anaconda3/envs/dl2022/lib/python3.10/site-packages (2.0.0)
Processing /scistor/informatica/dgi460/PROT/PROT
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Building wheels for collected packages: PROT
  Building wheel for PROT (setup.py): started
  Building wheel for PROT (setup.py): finished with status 'done'
  Created wheel for PROT: filename=PROT-0.0.1-py3-none-any.whl size=116825 sha256=c34950381d65540bcee923c67d4ea85e570f57cf18d0d084dd4e88504dcfaf32
  Stored in directory: /scratch/692450/pip-ephem-wheel-cache-wd4bgezg/wheels/f3/f3/d5/e95d019bbe728e863c8658a0c362e103b5264b28afecea62b9
Successfully built PROT
Installing collected packages: PROT
  Attempting uninstall: PROT
    Found existing installation: PROT 0.0.1
    Uninstalling PROT-0.0.1:
      Successfully uninstalled PROT-0.0.1
Successfully installed PROT-0.0.1
2024-03-24 07:48:25,067 - PROT.PROT.main - INFO - Building: PROT.models.ESM2_original_extended
FINETUNING CHOSEN: LoRA
Gradient Checkpointing 2
2024-03-24 07:48:33,279 - PROT.PROT.models.ESM2_original_extended.model - INFO - <init>: 
ESM2_original_extended(
  (embedding): ESM2Embedding(
    (model): ESM2(
      (embed_tokens): Embedding(33, 1280, padding_idx=1)
      (layers): ModuleList(
        (0): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (8): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (9): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (10): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (11): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (12): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (13): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (14): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (15): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (16): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (17): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (18): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (19): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (20): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (21): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (22): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (23): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (24): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (25): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (26): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (27): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (28): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (29): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (30): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (31): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (32): TransformerLoRALayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (k_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (v_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (q_LoRA): LowRankProjection(1280, 1280, rank=6, alpha=6)
            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (rot_emb): RotaryEmbedding()
          )
          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (fc1_LoRA): LowRankProjection(1280, 5120, rank=6, alpha=6)
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (fc2_LoRA): LowRankProjection(5120, 1280, rank=6, alpha=6)
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (contact_head): ContactPredictionHead(
        (regression): Linear(in_features=660, out_features=1, bias=True)
        (activation): Sigmoid()
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (lm_head): RobertaLMHead(
        (dense): Linear(in_features=1280, out_features=1280, bias=True)
        (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (conv): ModuleList(
    (0): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Conv1d(1280, 32, kernel_size=(129,), stride=(1,), padding=(64,))
      (2): ReLU()
    )
    (1): Sequential(
      (0): Dropout(p=0.5, inplace=False)
      (1): Conv1d(1280, 32, kernel_size=(257,), stride=(1,), padding=(128,))
      (2): ReLU()
    )
  )
  (batch_norm): BatchNorm1d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lstm): LSTM(1344, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)
  (lstm_dropout_layer): Dropout(p=0.5, inplace=False)
  (ss8): Sequential(
    (0): Linear(in_features=2048, out_features=8, bias=True)
  )
  (ss3): Sequential(
    (0): Linear(in_features=2048, out_features=3, bias=True)
  )
  (disorder): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (rsa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
    (1): Sigmoid()
  )
  (phi): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
    (1): Tanh()
  )
  (psi): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
    (1): Tanh()
  )
  (tasa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (thsa): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (lhp): Sequential(
    (0): Linear(in_features=2048, out_features=1, bias=True)
  )
  (hp_loc): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (lhp_loc): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (species): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
  (expression): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
  (aggregation): Sequential(
    (0): Linear(in_features=2048, out_features=2, bias=True)
  )
)
Trainable parameters: 61504231
2024-03-24 07:48:33,350 - PROT.PROT.main - INFO - Using devices [0] of available devices [0]
Using devices [0] of available devices [0]
2024-03-24 07:48:35,136 - PROT.PROT.main - INFO - Building: torch.optim.Adam
2024-03-24 07:48:35,140 - PROT.PROT.main - INFO - Building: PROT.data_loader.augmentation.sparse_token
FINETUNING CHOSEN: no finetuning
Gradient Checkpointing None
2024-03-24 07:48:36,727 - PROT.PROT.main - INFO - Building: PROT.data_loader.data_loaders.NSPDataLoader
2024-03-24 07:53:25,108 - PROT.PROT.main - INFO - Getting loss and metric function handles
2024-03-24 07:53:25,109 - PROT.PROT.main - INFO - Initialising trainer
GRADIENT ACCUMULATION 6
2024-03-24 07:53:25,120 - PROT.PROT.base.base_trainer - INFO - Starting training...
Multi Task Loss
SS8 : 1 // SS3: 5 // DIS: 5 // RSA: 100 // PHI: 5 // PSI: 5 // TASA: 1e-07 // THSA: 2e-06 // LHP: 5e-06 // HP LOC: 5 // LHP LOC: 5
2024-03-24 07:53:28,983 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [0/10308 (0%)] Loss: 32.823898
2024-03-24 07:57:56,441 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [900/10308 (9%)] Loss: 18.982620
2024-03-24 08:02:21,151 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [1800/10308 (17%)] Loss: 14.249796
2024-03-24 08:06:46,280 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [2700/10308 (26%)] Loss: 15.049016
2024-03-24 08:11:16,935 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [3600/10308 (35%)] Loss: 13.519443
2024-03-24 08:15:42,212 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [4500/10308 (44%)] Loss: 15.824095
2024-03-24 08:20:05,437 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [5400/10308 (52%)] Loss: 15.149643
2024-03-24 08:24:31,601 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [6300/10308 (61%)] Loss: 20.818672
2024-03-24 08:28:56,531 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [7200/10308 (70%)] Loss: 11.544285
2024-03-24 08:33:27,024 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [8100/10308 (79%)] Loss: 13.281397
2024-03-24 08:37:49,216 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [9000/10308 (87%)] Loss: 12.469225
2024-03-24 08:42:15,972 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 0 [9900/10308 (96%)] Loss: 11.747006
2024-03-24 08:45:49,585 - PROT.PROT.base.base_trainer - INFO - epoch          : 0
2024-03-24 08:45:49,586 - PROT.PROT.base.base_trainer - INFO - loss           : 15.092791580816113
2024-03-24 08:45:49,587 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.6514017389466366
2024-03-24 08:45:49,589 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.7981450359026591
2024-03-24 08:45:49,590 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.37567973928526044
2024-03-24 08:45:49,591 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.04766954305038477
2024-03-24 08:45:49,593 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.6897073520813137
2024-03-24 08:45:49,594 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.7201550093789896
2024-03-24 08:45:49,595 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 27.825557231903076
2024-03-24 08:45:49,596 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 37.284723122914635
2024-03-24 08:45:49,597 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 2828.0103174845376
2024-03-24 08:45:49,599 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 685.0427665710449
2024-03-24 08:45:49,600 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 512.7895641326904
2024-03-24 08:45:49,601 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.7480377426060537
2024-03-24 08:45:49,602 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.14052809743831554
2024-03-24 08:45:49,603 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.37074902405341464
2024-03-24 08:45:49,604 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.15430602120856443
2024-03-24 08:45:49,606 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.784318783186459
2024-03-24 08:45:49,607 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7378083975552633
2024-03-24 08:45:49,608 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.863414729103391
2024-03-24 08:45:49,609 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.5924006682722674
2024-03-24 08:45:49,610 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.00948179497912344
2024-03-24 08:45:49,611 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8050699713485268
2024-03-24 08:45:49,612 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8184518941654051
2024-03-24 08:45:49,614 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 17.54969466480382
2024-03-24 08:45:49,615 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 24.55701290989274
2024-03-24 08:45:49,616 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 1222.626114848795
2024-03-24 08:45:49,617 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 499.6771524788269
2024-03-24 08:45:49,618 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 466.70697426883936
2024-03-24 08:45:49,619 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8612180139965677
2024-03-24 08:45:49,620 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.06658952165999865
2024-03-24 08:45:49,622 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45786964480947306
2024-03-24 08:45:49,623 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.06008056345880307
2024-03-24 08:46:10,011 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch0.pth ...
2024-03-24 08:46:40,542 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 08:46:44,205 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [0/10308 (0%)] Loss: 11.950321
2024-03-24 08:51:09,200 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [900/10308 (9%)] Loss: 11.638906
2024-03-24 08:55:34,647 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [1800/10308 (17%)] Loss: 12.345125
2024-03-24 09:00:07,647 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [2700/10308 (26%)] Loss: 11.294516
2024-03-24 09:04:40,212 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [3600/10308 (35%)] Loss: 15.312585
2024-03-24 09:09:15,536 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [4500/10308 (44%)] Loss: 11.178654
2024-03-24 09:13:30,288 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [5400/10308 (52%)] Loss: 15.420104
2024-03-24 09:18:06,173 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [6300/10308 (61%)] Loss: 21.569393
2024-03-24 09:22:42,248 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [7200/10308 (70%)] Loss: 11.645812
2024-03-24 09:27:17,054 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [8100/10308 (79%)] Loss: 18.831045
2024-03-24 09:31:48,216 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [9000/10308 (87%)] Loss: 10.317247
2024-03-24 09:36:11,182 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 1 [9900/10308 (96%)] Loss: 11.460030
2024-03-24 09:39:32,452 - PROT.PROT.base.base_trainer - INFO - epoch          : 1
2024-03-24 09:39:32,454 - PROT.PROT.base.base_trainer - INFO - loss           : 12.673308637150047
2024-03-24 09:39:32,455 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7179858436187109
2024-03-24 09:39:32,457 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8418335318565369
2024-03-24 09:39:32,458 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5839308245728413
2024-03-24 09:39:32,459 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.011973800137639046
2024-03-24 09:39:32,461 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.7689404884974161
2024-03-24 09:39:32,462 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.7848971486091614
2024-03-24 09:39:32,463 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 18.0358301003774
2024-03-24 09:39:32,465 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 27.636285225550335
2024-03-24 09:39:32,466 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 1569.990109761556
2024-03-24 09:39:32,467 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 542.1115214029948
2024-03-24 09:39:32,468 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 350.4718945821126
2024-03-24 09:39:32,470 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8531610121329626
2024-03-24 09:39:32,471 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.08389184422170122
2024-03-24 09:39:32,472 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.42646080255508423
2024-03-24 09:39:32,473 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.07601387007161975
2024-03-24 09:39:32,474 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.422361113488455
2024-03-24 09:39:32,475 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7532586493835238
2024-03-24 09:39:32,477 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8666316842680928
2024-03-24 09:39:32,478 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6073188040924441
2024-03-24 09:39:32,479 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.011818492476230425
2024-03-24 09:39:32,480 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8098417115827328
2024-03-24 09:39:32,481 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8233913287685366
2024-03-24 09:39:32,482 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.627628745188133
2024-03-24 09:39:32,483 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 23.589765788004406
2024-03-24 09:39:32,485 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 1037.851484150904
2024-03-24 09:39:32,486 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 459.26698288442464
2024-03-24 09:39:32,487 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 440.5262807304129
2024-03-24 09:39:32,488 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8641822156746888
2024-03-24 09:39:32,489 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.06336529651770786
2024-03-24 09:39:32,491 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.46174958077344025
2024-03-24 09:39:32,492 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.06246817533051205
2024-03-24 09:39:55,958 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch1.pth ...
2024-03-24 09:40:29,948 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 09:40:33,348 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [0/10308 (0%)] Loss: 12.671610
2024-03-24 09:44:57,220 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [900/10308 (9%)] Loss: 11.855393
2024-03-24 09:49:20,544 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [1800/10308 (17%)] Loss: 11.282074
2024-03-24 09:53:56,656 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [2700/10308 (26%)] Loss: 12.062233
2024-03-24 09:58:24,993 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [3600/10308 (35%)] Loss: 14.438732
2024-03-24 10:02:55,050 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [4500/10308 (44%)] Loss: 12.914824
2024-03-24 10:07:41,593 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [5400/10308 (52%)] Loss: 11.567085
2024-03-24 10:12:14,504 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [6300/10308 (61%)] Loss: 11.228027
2024-03-24 10:16:50,929 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [7200/10308 (70%)] Loss: 11.060877
2024-03-24 10:21:25,343 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [8100/10308 (79%)] Loss: 11.335329
2024-03-24 10:25:47,443 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [9000/10308 (87%)] Loss: 16.779816
2024-03-24 10:30:12,402 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 2 [9900/10308 (96%)] Loss: 11.411757
2024-03-24 10:33:41,229 - PROT.PROT.base.base_trainer - INFO - epoch          : 2
2024-03-24 10:33:41,231 - PROT.PROT.base.base_trainer - INFO - loss           : 12.35685455806043
2024-03-24 10:33:41,232 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.752028668920199
2024-03-24 10:33:41,233 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8740006337563196
2024-03-24 10:33:41,235 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5472009107470512
2024-03-24 10:33:41,236 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.012780379795003682
2024-03-24 10:33:41,238 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8058409045139948
2024-03-24 10:33:41,239 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8203772703806559
2024-03-24 10:33:41,240 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 16.7142919699351
2024-03-24 10:33:41,242 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 23.374111811319988
2024-03-24 10:33:41,243 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 1023.2315012613932
2024-03-24 10:33:41,244 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 528.7816314697266
2024-03-24 10:33:41,245 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 453.37174224853516
2024-03-24 10:33:41,247 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8525042732556661
2024-03-24 10:33:41,248 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.08837194616595904
2024-03-24 10:33:41,249 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.44288499901692074
2024-03-24 10:33:41,250 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.09746551762024562
2024-03-24 10:33:41,253 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.138496193058817
2024-03-24 10:33:41,255 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7595068800273417
2024-03-24 10:33:41,256 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8719224599894563
2024-03-24 10:33:41,257 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6233690917866503
2024-03-24 10:33:41,259 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.014911801556410522
2024-03-24 10:33:41,260 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8146397399946332
2024-03-24 10:33:41,261 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8285677735436007
2024-03-24 10:33:41,263 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.404296656816207
2024-03-24 10:33:41,264 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 23.077151926681125
2024-03-24 10:33:41,265 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 920.0884359014871
2024-03-24 10:33:41,266 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 423.88013457548135
2024-03-24 10:33:41,267 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 421.37165130108485
2024-03-24 10:33:41,268 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8563582485892236
2024-03-24 10:33:41,269 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.092413505058172
2024-03-24 10:33:41,271 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45733300032870794
2024-03-24 10:33:41,272 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.0858946148567314
2024-03-24 10:33:59,620 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch2.pth ...
2024-03-24 10:34:29,728 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 10:34:32,787 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [0/10308 (0%)] Loss: 11.378451
2024-03-24 10:39:01,664 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [900/10308 (9%)] Loss: 11.275283
2024-03-24 10:43:35,317 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [1800/10308 (17%)] Loss: 9.727878
2024-03-24 10:48:17,918 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [2700/10308 (26%)] Loss: 11.338572
2024-03-24 10:52:57,809 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [3600/10308 (35%)] Loss: 11.083149
2024-03-24 10:57:21,381 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [4500/10308 (44%)] Loss: 9.959291
2024-03-24 11:01:49,857 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [5400/10308 (52%)] Loss: 11.526236
2024-03-24 11:06:17,069 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [6300/10308 (61%)] Loss: 11.592731
2024-03-24 11:10:46,036 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [7200/10308 (70%)] Loss: 10.729944
2024-03-24 11:15:15,195 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [8100/10308 (79%)] Loss: 9.811034
2024-03-24 11:19:33,973 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [9000/10308 (87%)] Loss: 10.472807
2024-03-24 11:24:05,265 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 3 [9900/10308 (96%)] Loss: 10.314548
2024-03-24 11:27:30,275 - PROT.PROT.base.base_trainer - INFO - epoch          : 3
2024-03-24 11:27:30,276 - PROT.PROT.base.base_trainer - INFO - loss           : 12.210679007807265
2024-03-24 11:27:30,277 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7928485870361328
2024-03-24 11:27:30,279 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.891513854265213
2024-03-24 11:27:30,280 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5907562052210172
2024-03-24 11:27:30,281 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.010413721698569134
2024-03-24 11:27:30,282 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8403367698192596
2024-03-24 11:27:30,284 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8567522168159485
2024-03-24 11:27:30,285 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 15.577431281407675
2024-03-24 11:27:30,286 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 20.61155613263448
2024-03-24 11:27:30,287 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 575.3871765136719
2024-03-24 11:27:30,288 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 216.11459604899088
2024-03-24 11:27:30,289 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 302.20465596516925
2024-03-24 11:27:30,291 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8819157133499781
2024-03-24 11:27:30,292 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.06653648459662993
2024-03-24 11:27:30,293 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.46761317799488705
2024-03-24 11:27:30,294 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.05818019760772586
2024-03-24 11:27:30,295 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.240235496711026
2024-03-24 11:27:30,297 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7657389216317462
2024-03-24 11:27:30,298 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8717449869396942
2024-03-24 11:27:30,299 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.585586794447292
2024-03-24 11:27:30,300 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.006405996682265829
2024-03-24 11:27:30,301 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8170109429702548
2024-03-24 11:27:30,302 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8299977048076826
2024-03-24 11:27:30,303 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.376857708301053
2024-03-24 11:27:30,305 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.927656129717388
2024-03-24 11:27:30,306 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 1062.4229670521079
2024-03-24 11:27:30,307 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 425.45153950765126
2024-03-24 11:27:30,308 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 421.4446852708655
2024-03-24 11:27:30,309 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8645756267882013
2024-03-24 11:27:30,310 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.06789296139368584
2024-03-24 11:27:30,311 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45475586225902437
2024-03-24 11:27:30,312 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.06585190191706003
2024-03-24 11:27:47,727 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch3.pth ...
2024-03-24 11:27:50,753 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [0/10308 (0%)] Loss: 10.285512
2024-03-24 11:32:10,162 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [900/10308 (9%)] Loss: 13.386670
2024-03-24 11:36:42,101 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [1800/10308 (17%)] Loss: 11.513420
2024-03-24 11:41:20,431 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [2700/10308 (26%)] Loss: 9.955940
2024-03-24 11:45:51,919 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [3600/10308 (35%)] Loss: 10.154528
2024-03-24 11:50:23,007 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [4500/10308 (44%)] Loss: 11.674269
2024-03-24 11:54:42,770 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [5400/10308 (52%)] Loss: 10.115334
2024-03-24 11:59:18,222 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [6300/10308 (61%)] Loss: 11.986958
2024-03-24 12:03:35,939 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [7200/10308 (70%)] Loss: 10.755749
2024-03-24 12:08:16,770 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [8100/10308 (79%)] Loss: 13.223715
2024-03-24 12:12:44,678 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [9000/10308 (87%)] Loss: 13.205929
2024-03-24 12:17:13,769 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 4 [9900/10308 (96%)] Loss: 10.339387
2024-03-24 12:20:31,457 - PROT.PROT.base.base_trainer - INFO - epoch          : 4
2024-03-24 12:20:31,458 - PROT.PROT.base.base_trainer - INFO - loss           : 12.052382518498845
2024-03-24 12:20:31,460 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7569154848655065
2024-03-24 12:20:31,461 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8635041316350301
2024-03-24 12:20:31,462 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.6018613658168099
2024-03-24 12:20:31,464 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.007959108198216805
2024-03-24 12:20:31,465 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8154385536909103
2024-03-24 12:20:31,466 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8253564437230428
2024-03-24 12:20:31,468 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 17.773087739944458
2024-03-24 12:20:31,469 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 24.538568655649822
2024-03-24 12:20:31,470 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 495.1351369222005
2024-03-24 12:20:31,471 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 339.59798940022785
2024-03-24 12:20:31,472 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 290.18032964070636
2024-03-24 12:20:31,473 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.862500881155332
2024-03-24 12:20:31,474 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.09773079833636682
2024-03-24 12:20:31,475 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.41007424890995026
2024-03-24 12:20:31,476 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.09844857268035412
2024-03-24 12:20:31,477 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.440020015758781
2024-03-24 12:20:31,479 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.766611303460554
2024-03-24 12:20:31,480 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.875412202959131
2024-03-24 12:20:31,481 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6257731025313402
2024-03-24 12:20:31,482 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.01462370163255897
2024-03-24 12:20:31,483 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8175645493713252
2024-03-24 12:20:31,484 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8299416738022738
2024-03-24 12:20:31,485 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.188698787970736
2024-03-24 12:20:31,486 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.678149086082993
2024-03-24 12:20:31,488 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 969.6250691713002
2024-03-24 12:20:31,489 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 469.76950442043176
2024-03-24 12:20:31,490 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 511.6343299471584
2024-03-24 12:20:31,491 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8666652471816848
2024-03-24 12:20:31,492 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.05939678393297475
2024-03-24 12:20:31,493 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4584926379452772
2024-03-24 12:20:31,494 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.059848035775070044
2024-03-24 12:20:49,079 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch4.pth ...
2024-03-24 12:20:51,470 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [0/10308 (0%)] Loss: 10.979999
2024-03-24 12:25:19,578 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [900/10308 (9%)] Loss: 12.052693
2024-03-24 12:29:41,278 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [1800/10308 (17%)] Loss: 12.451518
2024-03-24 12:34:12,969 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [2700/10308 (26%)] Loss: 12.700374
2024-03-24 12:38:52,568 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [3600/10308 (35%)] Loss: 11.586298
2024-03-24 12:43:32,153 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [4500/10308 (44%)] Loss: 10.424303
2024-03-24 12:48:03,226 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [5400/10308 (52%)] Loss: 10.002607
2024-03-24 12:52:39,116 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [6300/10308 (61%)] Loss: 11.414688
2024-03-24 12:57:05,620 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [7200/10308 (70%)] Loss: 13.553132
2024-03-24 13:01:35,758 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [8100/10308 (79%)] Loss: 10.728093
2024-03-24 13:05:51,790 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [9000/10308 (87%)] Loss: 11.824198
2024-03-24 13:10:17,200 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 5 [9900/10308 (96%)] Loss: 11.157487
2024-03-24 13:13:40,238 - PROT.PROT.base.base_trainer - INFO - epoch          : 5
2024-03-24 13:13:40,240 - PROT.PROT.base.base_trainer - INFO - loss           : 11.931338674046335
2024-03-24 13:13:40,241 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.8021588971217474
2024-03-24 13:13:40,242 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8909475753704706
2024-03-24 13:13:40,244 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.6475580303619305
2024-03-24 13:13:40,245 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.008733480761293322
2024-03-24 13:13:40,246 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.812189648548762
2024-03-24 13:13:40,247 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8214495033025742
2024-03-24 13:13:40,249 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 14.630993366241455
2024-03-24 13:13:40,250 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 21.12712796529134
2024-03-24 13:13:40,251 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 835.0218251546224
2024-03-24 13:13:40,252 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 408.44886016845703
2024-03-24 13:13:40,253 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 447.0841344197591
2024-03-24 13:13:40,255 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8785973340272903
2024-03-24 13:13:40,256 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.07844657947619756
2024-03-24 13:13:40,257 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.49137359609206516
2024-03-24 13:13:40,258 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.05856676686865588
2024-03-24 13:13:40,259 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.126915329936686
2024-03-24 13:13:40,261 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7689769553962229
2024-03-24 13:13:40,262 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8755694987369199
2024-03-24 13:13:40,263 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.630361451678033
2024-03-24 13:13:40,264 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.013237904945845506
2024-03-24 13:13:40,265 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8188095045485619
2024-03-24 13:13:40,267 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8313939803420838
2024-03-24 13:13:40,268 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.319248591841806
2024-03-24 13:13:40,269 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.79455585057445
2024-03-24 13:13:40,270 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 1005.0412256444952
2024-03-24 13:13:40,271 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 435.1304057814538
2024-03-24 13:13:40,272 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 400.8668235835114
2024-03-24 13:13:40,273 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8669601332437509
2024-03-24 13:13:40,275 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.046406315985853985
2024-03-24 13:13:40,276 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4633211897088153
2024-03-24 13:13:40,277 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.04285513571157667
2024-03-24 13:13:57,989 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch5.pth ...
2024-03-24 13:14:24,105 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 13:14:26,845 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [0/10308 (0%)] Loss: 10.465410
2024-03-24 13:19:04,568 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [900/10308 (9%)] Loss: 9.987782
2024-03-24 13:23:36,827 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [1800/10308 (17%)] Loss: 12.050364
2024-03-24 13:28:04,631 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [2700/10308 (26%)] Loss: 11.737274
2024-03-24 13:32:28,961 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [3600/10308 (35%)] Loss: 14.379066
2024-03-24 13:37:00,696 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [4500/10308 (44%)] Loss: 11.494148
2024-03-24 13:41:29,617 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [5400/10308 (52%)] Loss: 10.779965
2024-03-24 13:45:51,962 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [6300/10308 (61%)] Loss: 12.576398
2024-03-24 13:50:23,191 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [7200/10308 (70%)] Loss: 10.824108
2024-03-24 13:54:49,769 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [8100/10308 (79%)] Loss: 11.210306
2024-03-24 13:59:17,088 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [9000/10308 (87%)] Loss: 11.385013
2024-03-24 14:03:52,323 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 6 [9900/10308 (96%)] Loss: 10.299188
2024-03-24 14:07:15,533 - PROT.PROT.base.base_trainer - INFO - epoch          : 6
2024-03-24 14:07:15,534 - PROT.PROT.base.base_trainer - INFO - loss           : 11.837735820922392
2024-03-24 14:07:15,536 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7747956116994222
2024-03-24 14:07:15,537 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8765160739421844
2024-03-24 14:07:15,538 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5982985744873682
2024-03-24 14:07:15,539 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.01554722742487987
2024-03-24 14:07:15,541 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8265343507130941
2024-03-24 14:07:15,542 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8354989588260651
2024-03-24 14:07:15,543 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 16.07458186149597
2024-03-24 14:07:15,545 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 23.049491723378498
2024-03-24 14:07:15,546 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 855.2016932169596
2024-03-24 14:07:15,547 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 354.1719487508138
2024-03-24 14:07:15,548 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 314.84485753377277
2024-03-24 14:07:15,549 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.855602815747261
2024-03-24 14:07:15,550 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.07897609534362952
2024-03-24 14:07:15,551 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.4584267660975456
2024-03-24 14:07:15,553 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.07238916478430231
2024-03-24 14:07:15,554 - PROT.PROT.base.base_trainer - INFO - val_loss       : 11.969028450026283
2024-03-24 14:07:15,555 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7709043646210674
2024-03-24 14:07:15,556 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8755386980917181
2024-03-24 14:07:15,557 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6380658938216107
2024-03-24 14:07:15,558 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.018764871373111933
2024-03-24 14:07:15,560 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8193616423879603
2024-03-24 14:07:15,561 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8316106665398362
2024-03-24 14:07:15,562 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.051896679445388
2024-03-24 14:07:15,563 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.627028160869415
2024-03-24 14:07:15,564 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 857.6798851815537
2024-03-24 14:07:15,565 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 407.9784463903561
2024-03-24 14:07:15,567 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 410.3982580051211
2024-03-24 14:07:15,568 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8627254031461103
2024-03-24 14:07:15,569 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.08764133707798907
2024-03-24 14:07:15,570 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4627265084768573
2024-03-24 14:07:15,571 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.07893990074384037
2024-03-24 14:07:32,707 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch6.pth ...
2024-03-24 14:07:54,689 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 14:07:57,065 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [0/10308 (0%)] Loss: 10.468961
2024-03-24 14:12:08,981 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [900/10308 (9%)] Loss: 11.172694
2024-03-24 14:16:32,285 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [1800/10308 (17%)] Loss: 12.289186
2024-03-24 14:20:59,750 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [2700/10308 (26%)] Loss: 11.651531
2024-03-24 14:25:30,816 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [3600/10308 (35%)] Loss: 11.175552
2024-03-24 14:30:01,628 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [4500/10308 (44%)] Loss: 12.593143
2024-03-24 14:34:39,320 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [5400/10308 (52%)] Loss: 11.246062
2024-03-24 14:39:12,257 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [6300/10308 (61%)] Loss: 10.607619
2024-03-24 14:43:38,072 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [7200/10308 (70%)] Loss: 10.012788
2024-03-24 14:48:03,563 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [8100/10308 (79%)] Loss: 10.355875
2024-03-24 14:52:38,218 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [9000/10308 (87%)] Loss: 10.371776
2024-03-24 14:56:59,212 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 7 [9900/10308 (96%)] Loss: 11.082382
2024-03-24 15:00:26,326 - PROT.PROT.base.base_trainer - INFO - epoch          : 7
2024-03-24 15:00:26,328 - PROT.PROT.base.base_trainer - INFO - loss           : 11.782511431847455
2024-03-24 15:00:26,329 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7840728064378103
2024-03-24 15:00:26,331 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8888612687587738
2024-03-24 15:00:26,332 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.6590231731534004
2024-03-24 15:00:26,334 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.011939130015283203
2024-03-24 15:00:26,335 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8192927042643229
2024-03-24 15:00:26,336 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8299205700556437
2024-03-24 15:00:26,337 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 15.746534665425619
2024-03-24 15:00:26,339 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 22.165462176005047
2024-03-24 15:00:26,340 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 888.9355951944987
2024-03-24 15:00:26,341 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 280.4500850041707
2024-03-24 15:00:26,343 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 253.13337262471518
2024-03-24 15:00:26,344 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8610517829656601
2024-03-24 15:00:26,345 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.08672844851389527
2024-03-24 15:00:26,346 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.42795056849718094
2024-03-24 15:00:26,348 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.07273434816549222
2024-03-24 15:00:26,349 - PROT.PROT.base.base_trainer - INFO - val_loss       : 11.939164173998956
2024-03-24 15:00:26,350 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7699362382677648
2024-03-24 15:00:26,351 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8749549176640177
2024-03-24 15:00:26,353 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6176112407027071
2024-03-24 15:00:26,354 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.010563988692635787
2024-03-24 15:00:26,355 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8187290333293901
2024-03-24 15:00:26,356 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8315141450654977
2024-03-24 15:00:26,358 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.122373698822248
2024-03-24 15:00:26,359 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.642147885917296
2024-03-24 15:00:26,361 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 852.7608473098586
2024-03-24 15:00:26,362 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 402.41621953534906
2024-03-24 15:00:26,363 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 393.2992358330871
2024-03-24 15:00:26,364 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8645546722236155
2024-03-24 15:00:26,365 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.054371919526763235
2024-03-24 15:00:26,367 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4543091339983623
2024-03-24 15:00:26,368 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.051821726254905776
2024-03-24 15:00:48,524 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch7.pth ...
2024-03-24 15:01:15,446 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 15:01:19,135 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [0/10308 (0%)] Loss: 11.593988
2024-03-24 15:05:46,669 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [900/10308 (9%)] Loss: 10.542417
2024-03-24 15:10:22,209 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [1800/10308 (17%)] Loss: 11.219037
2024-03-24 15:14:54,198 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [2700/10308 (26%)] Loss: 10.923511
2024-03-24 15:19:13,727 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [3600/10308 (35%)] Loss: 12.706060
2024-03-24 15:23:48,688 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [4500/10308 (44%)] Loss: 11.104981
2024-03-24 15:28:22,805 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [5400/10308 (52%)] Loss: 10.619091
2024-03-24 15:32:58,422 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [6300/10308 (61%)] Loss: 10.632733
2024-03-24 15:37:32,091 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [7200/10308 (70%)] Loss: 12.255760
2024-03-24 15:42:00,281 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [8100/10308 (79%)] Loss: 10.965235
2024-03-24 15:46:29,256 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [9000/10308 (87%)] Loss: 10.432702
2024-03-24 15:50:57,211 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 8 [9900/10308 (96%)] Loss: 10.850493
2024-03-24 15:54:23,482 - PROT.PROT.base.base_trainer - INFO - epoch          : 8
2024-03-24 15:54:23,484 - PROT.PROT.base.base_trainer - INFO - loss           : 11.675288191494978
2024-03-24 15:54:23,485 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7870650490125021
2024-03-24 15:54:23,487 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8901690791050593
2024-03-24 15:54:23,489 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.7226783402941444
2024-03-24 15:54:23,490 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.009437373131125545
2024-03-24 15:54:23,491 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8325086683034897
2024-03-24 15:54:23,492 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.842520554860433
2024-03-24 15:54:23,493 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 16.29202938079834
2024-03-24 15:54:23,495 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 21.941970348358154
2024-03-24 15:54:23,496 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 599.5718892415365
2024-03-24 15:54:23,497 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 354.84620094299316
2024-03-24 15:54:23,498 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 387.93124262491864
2024-03-24 15:54:23,499 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8716532091299692
2024-03-24 15:54:23,501 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.07337192220923801
2024-03-24 15:54:23,502 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.47152481352289516
2024-03-24 15:54:23,503 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.08533617854118347
2024-03-24 15:54:23,504 - PROT.PROT.base.base_trainer - INFO - val_loss       : 11.921874169493954
2024-03-24 15:54:23,505 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.770118331667242
2024-03-24 15:54:23,506 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8765152122041836
2024-03-24 15:54:23,507 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6282248076548065
2024-03-24 15:54:23,508 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.0151919368181955
2024-03-24 15:54:23,509 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8216761629959753
2024-03-24 15:54:23,510 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8339109364690815
2024-03-24 15:54:23,511 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.329364275140517
2024-03-24 15:54:23,512 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.48351018807105
2024-03-24 15:54:23,514 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 856.1152752950183
2024-03-24 15:54:23,515 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 397.71257425850166
2024-03-24 15:54:23,516 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 410.54262427298346
2024-03-24 15:54:23,517 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8685384974408902
2024-03-24 15:54:23,518 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.046310591841451754
2024-03-24 15:54:23,519 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4599538651434964
2024-03-24 15:54:23,520 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.04259564828106888
2024-03-24 15:54:44,210 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch8.pth ...
2024-03-24 15:55:14,507 - PROT.PROT.base.base_trainer - INFO - Saving current best: saved/basic_w_patches/0324-075325/checkpoints/model_best.pth
2024-03-24 15:55:17,726 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [0/10308 (0%)] Loss: 10.633272
2024-03-24 15:59:58,115 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [900/10308 (9%)] Loss: 12.087936
2024-03-24 16:04:24,457 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [1800/10308 (17%)] Loss: 11.491213
2024-03-24 16:08:54,156 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [2700/10308 (26%)] Loss: 14.145969
2024-03-24 16:13:19,931 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [3600/10308 (35%)] Loss: 11.691182
2024-03-24 16:17:44,384 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [4500/10308 (44%)] Loss: 13.362975
2024-03-24 16:22:15,760 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [5400/10308 (52%)] Loss: 11.785266
2024-03-24 16:26:58,414 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [6300/10308 (61%)] Loss: 11.608631
2024-03-24 16:31:18,623 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [7200/10308 (70%)] Loss: 11.502286
2024-03-24 16:35:51,399 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [8100/10308 (79%)] Loss: 11.500662
2024-03-24 16:40:19,527 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [9000/10308 (87%)] Loss: 11.421977
2024-03-24 16:44:52,041 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 9 [9900/10308 (96%)] Loss: 12.648176
2024-03-24 16:48:18,086 - PROT.PROT.base.base_trainer - INFO - epoch          : 9
2024-03-24 16:48:18,088 - PROT.PROT.base.base_trainer - INFO - loss           : 11.539377502069042
2024-03-24 16:48:18,089 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7410015960534414
2024-03-24 16:48:18,091 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8635357071955999
2024-03-24 16:48:18,092 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.6442473443845907
2024-03-24 16:48:18,093 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.004331327897186081
2024-03-24 16:48:18,095 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.7946756978829702
2024-03-24 16:48:18,096 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8110302189985911
2024-03-24 16:48:18,097 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 18.172677914301556
2024-03-24 16:48:18,098 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 26.05107307434082
2024-03-24 16:48:18,100 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 886.9496205647787
2024-03-24 16:48:18,101 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 426.0456657409668
2024-03-24 16:48:18,102 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 363.1752052307129
2024-03-24 16:48:18,103 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8312530765930811
2024-03-24 16:48:18,104 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.09333275180930893
2024-03-24 16:48:18,106 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.41187019397815067
2024-03-24 16:48:18,107 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.09333386396368344
2024-03-24 16:48:18,108 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.061495133431634
2024-03-24 16:48:18,109 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7696926923695525
2024-03-24 16:48:18,111 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8750967805675914
2024-03-24 16:48:18,112 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.5813559699645474
2024-03-24 16:48:18,113 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.005810356111161761
2024-03-24 16:48:18,114 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8198012703019315
2024-03-24 16:48:18,116 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8327545740287682
2024-03-24 16:48:18,117 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.21692095471484
2024-03-24 16:48:18,118 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.59150367469365
2024-03-24 16:48:18,120 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 852.1480510683517
2024-03-24 16:48:18,122 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 404.62084515420275
2024-03-24 16:48:18,123 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 399.3137811822645
2024-03-24 16:48:18,124 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8541029754380018
2024-03-24 16:48:18,126 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.11589601963614131
2024-03-24 16:48:18,127 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45389701821927214
2024-03-24 16:48:18,128 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.10781453947306394
2024-03-24 16:48:35,728 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch9.pth ...
2024-03-24 16:48:38,987 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [0/10308 (0%)] Loss: 12.888318
2024-03-24 16:53:14,340 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [900/10308 (9%)] Loss: 11.274534
2024-03-24 16:57:54,314 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [1800/10308 (17%)] Loss: 9.830637
2024-03-24 17:02:14,713 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [2700/10308 (26%)] Loss: 14.038734
2024-03-24 17:06:50,172 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [3600/10308 (35%)] Loss: 10.613302
2024-03-24 17:11:10,929 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [4500/10308 (44%)] Loss: 12.579184
2024-03-24 17:15:45,147 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [5400/10308 (52%)] Loss: 10.912118
2024-03-24 17:20:23,762 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [6300/10308 (61%)] Loss: 10.360765
2024-03-24 17:24:52,490 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [7200/10308 (70%)] Loss: 12.123348
2024-03-24 17:29:27,725 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [8100/10308 (79%)] Loss: 10.320188
2024-03-24 17:33:55,479 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [9000/10308 (87%)] Loss: 10.346517
2024-03-24 17:38:10,841 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 10 [9900/10308 (96%)] Loss: 12.887794
2024-03-24 17:41:38,023 - PROT.PROT.base.base_trainer - INFO - epoch          : 10
2024-03-24 17:41:38,024 - PROT.PROT.base.base_trainer - INFO - loss           : 11.472457956069421
2024-03-24 17:41:38,026 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7574443171421686
2024-03-24 17:41:38,027 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.868648370107015
2024-03-24 17:41:38,029 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.4804483229915301
2024-03-24 17:41:38,030 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.011827939005646234
2024-03-24 17:41:38,032 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8063409527142843
2024-03-24 17:41:38,033 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.817007303237915
2024-03-24 17:41:38,034 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 17.828799327214558
2024-03-24 17:41:38,035 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 23.77671480178833
2024-03-24 17:41:38,036 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 585.73370997111
2024-03-24 17:41:38,037 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 295.6809991200765
2024-03-24 17:41:38,038 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 376.3668467203776
2024-03-24 17:41:38,040 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8713696748018265
2024-03-24 17:41:38,041 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.0702949163193504
2024-03-24 17:41:38,042 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.557994045317173
2024-03-24 17:41:38,043 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.07082781071464221
2024-03-24 17:41:38,044 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.075427445978256
2024-03-24 17:41:38,045 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7709671173148489
2024-03-24 17:41:38,046 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8765922006205878
2024-03-24 17:41:38,047 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6383151121547521
2024-03-24 17:41:38,049 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.013737390685256921
2024-03-24 17:41:38,050 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8202462234840182
2024-03-24 17:41:38,051 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8333317514275272
2024-03-24 17:41:38,052 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.262677183890254
2024-03-24 17:41:38,053 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.315692032395255
2024-03-24 17:41:38,054 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 818.484651459979
2024-03-24 17:41:38,055 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 424.98752347657603
2024-03-24 17:41:38,057 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 405.42285742530964
2024-03-24 17:41:38,058 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8608490515679011
2024-03-24 17:41:38,059 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.09457718566527445
2024-03-24 17:41:38,060 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45999108590323107
2024-03-24 17:41:38,061 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.08524013926684032
2024-03-24 17:42:01,208 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch10.pth ...
2024-03-24 17:42:04,076 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [0/10308 (0%)] Loss: 10.405160
2024-03-24 17:46:19,104 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [900/10308 (9%)] Loss: 10.965557
2024-03-24 17:50:43,144 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [1800/10308 (17%)] Loss: 11.772206
2024-03-24 17:55:08,596 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [2700/10308 (26%)] Loss: 11.133170
2024-03-24 17:59:42,218 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [3600/10308 (35%)] Loss: 12.033237
2024-03-24 18:04:11,599 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [4500/10308 (44%)] Loss: 10.495075
2024-03-24 18:08:39,080 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [5400/10308 (52%)] Loss: 10.382346
2024-03-24 18:13:13,049 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [6300/10308 (61%)] Loss: 9.706444
2024-03-24 18:17:47,701 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [7200/10308 (70%)] Loss: 10.060539
2024-03-24 18:22:30,230 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [8100/10308 (79%)] Loss: 14.667892
2024-03-24 18:27:05,134 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [9000/10308 (87%)] Loss: 10.396767
2024-03-24 18:31:32,667 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 11 [9900/10308 (96%)] Loss: 12.163618
2024-03-24 18:34:54,901 - PROT.PROT.base.base_trainer - INFO - epoch          : 11
2024-03-24 18:34:54,902 - PROT.PROT.base.base_trainer - INFO - loss           : 11.369651793508236
2024-03-24 18:34:54,904 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7701543470223745
2024-03-24 18:34:54,905 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8696922659873962
2024-03-24 18:34:54,906 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.7139622643589973
2024-03-24 18:34:54,907 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.007132939848816022
2024-03-24 18:34:54,909 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.7947393010059992
2024-03-24 18:34:54,910 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8009413133064905
2024-03-24 18:34:54,911 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 17.44199291865031
2024-03-24 18:34:54,912 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 25.105217933654785
2024-03-24 18:34:54,914 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 606.3220367431641
2024-03-24 18:34:54,915 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 282.6735019683838
2024-03-24 18:34:54,916 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 273.6543032328288
2024-03-24 18:34:54,917 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8730599582195282
2024-03-24 18:34:54,919 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.06197416859989365
2024-03-24 18:34:54,920 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.48651598393917084
2024-03-24 18:34:54,921 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.06351147529979546
2024-03-24 18:34:54,922 - PROT.PROT.base.base_trainer - INFO - val_loss       : 11.971716159384188
2024-03-24 18:34:54,923 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.77285986863819
2024-03-24 18:34:54,925 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8779823655791829
2024-03-24 18:34:54,926 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6302661274334391
2024-03-24 18:34:54,927 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.014315443888725025
2024-03-24 18:34:54,928 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8211524256700959
2024-03-24 18:34:54,929 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8335832053884809
2024-03-24 18:34:54,931 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 15.940320681821817
2024-03-24 18:34:54,932 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.454175533843657
2024-03-24 18:34:54,933 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 855.6327839108851
2024-03-24 18:34:54,934 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 405.6866346091802
2024-03-24 18:34:54,935 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 395.3005314506728
2024-03-24 18:34:54,937 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8675961424778034
2024-03-24 18:34:54,938 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.06876853151084486
2024-03-24 18:34:54,939 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4583407856648397
2024-03-24 18:34:54,940 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.06346756742717716
2024-03-24 18:35:19,123 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch11.pth ...
2024-03-24 18:35:22,047 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [0/10308 (0%)] Loss: 10.555385
2024-03-24 18:39:40,772 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [900/10308 (9%)] Loss: 10.930720
2024-03-24 18:44:01,544 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [1800/10308 (17%)] Loss: 12.560929
2024-03-24 18:48:32,211 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [2700/10308 (26%)] Loss: 10.231289
2024-03-24 18:53:07,329 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [3600/10308 (35%)] Loss: 9.761407
2024-03-24 18:57:45,328 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [4500/10308 (44%)] Loss: 10.382537
2024-03-24 19:02:11,551 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [5400/10308 (52%)] Loss: 11.476009
2024-03-24 19:06:38,957 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [6300/10308 (61%)] Loss: 12.098417
2024-03-24 19:11:02,354 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [7200/10308 (70%)] Loss: 10.836873
2024-03-24 19:15:37,416 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [8100/10308 (79%)] Loss: 10.341014
2024-03-24 19:20:11,320 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [9000/10308 (87%)] Loss: 10.553349
2024-03-24 19:24:45,007 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 12 [9900/10308 (96%)] Loss: 9.326049
2024-03-24 19:28:13,942 - PROT.PROT.base.base_trainer - INFO - epoch          : 12
2024-03-24 19:28:13,944 - PROT.PROT.base.base_trainer - INFO - loss           : 11.360670941884186
2024-03-24 19:28:13,945 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7776631365219752
2024-03-24 19:28:13,946 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8870981832345327
2024-03-24 19:28:13,948 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5960791905721029
2024-03-24 19:28:13,949 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.00980308945872821
2024-03-24 19:28:13,950 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8369541068871816
2024-03-24 19:28:13,951 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8446387151877085
2024-03-24 19:28:13,953 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 15.821749528249105
2024-03-24 19:28:13,954 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 21.4714613755544
2024-03-24 19:28:13,955 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 696.6258977254232
2024-03-24 19:28:13,957 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 360.9612693786621
2024-03-24 19:28:13,958 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 217.10528818766275
2024-03-24 19:28:13,959 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8793217291434606
2024-03-24 19:28:13,960 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.07816739566624165
2024-03-24 19:28:13,962 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.45815253009398776
2024-03-24 19:28:13,963 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.0875662265655895
2024-03-24 19:28:13,964 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.113766985185912
2024-03-24 19:28:13,965 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7732064766857457
2024-03-24 19:28:13,967 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8773807059574831
2024-03-24 19:28:13,968 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6179228382451194
2024-03-24 19:28:13,969 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.013158308436391304
2024-03-24 19:28:13,970 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8208797969941284
2024-03-24 19:28:13,972 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8330795451503838
2024-03-24 19:28:13,973 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 15.93124851353494
2024-03-24 19:28:13,974 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.329581709365563
2024-03-24 19:28:13,975 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 861.6620452148888
2024-03-24 19:28:13,977 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 409.0507529846417
2024-03-24 19:28:13,978 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 431.55644082495206
2024-03-24 19:28:13,979 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8627877680797859
2024-03-24 19:28:13,981 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.07420297344885354
2024-03-24 19:28:13,982 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45642956821900893
2024-03-24 19:28:13,983 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.07108661027047852
2024-03-24 19:28:39,547 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch12.pth ...
2024-03-24 19:28:42,825 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [0/10308 (0%)] Loss: 9.963652
2024-03-24 19:33:08,148 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [900/10308 (9%)] Loss: 10.878824
2024-03-24 19:37:41,615 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [1800/10308 (17%)] Loss: 10.051476
2024-03-24 19:42:10,466 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [2700/10308 (26%)] Loss: 10.624490
2024-03-24 19:46:32,964 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [3600/10308 (35%)] Loss: 14.208067
2024-03-24 19:51:00,601 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [4500/10308 (44%)] Loss: 11.760918
2024-03-24 19:55:32,820 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [5400/10308 (52%)] Loss: 12.247862
2024-03-24 19:59:57,552 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [6300/10308 (61%)] Loss: 11.829957
2024-03-24 20:04:33,411 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [7200/10308 (70%)] Loss: 9.486152
2024-03-24 20:09:01,418 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [8100/10308 (79%)] Loss: 10.016994
2024-03-24 20:13:37,540 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [9000/10308 (87%)] Loss: 11.069519
2024-03-24 20:18:11,440 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 13 [9900/10308 (96%)] Loss: 10.916206
2024-03-24 20:21:30,408 - PROT.PROT.base.base_trainer - INFO - epoch          : 13
2024-03-24 20:21:30,409 - PROT.PROT.base.base_trainer - INFO - loss           : 11.280147214919507
2024-03-24 20:21:30,411 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7611882289250692
2024-03-24 20:21:30,412 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8747205833594004
2024-03-24 20:21:30,413 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.7123320053021113
2024-03-24 20:21:30,415 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.01140368584310636
2024-03-24 20:21:30,416 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.8143919507662455
2024-03-24 20:21:30,418 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.8264560699462891
2024-03-24 20:21:30,419 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 17.67665449778239
2024-03-24 20:21:30,420 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 24.571159203847248
2024-03-24 20:21:30,421 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 637.9194774627686
2024-03-24 20:21:30,423 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 298.0248209635417
2024-03-24 20:21:30,424 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 272.0347409248352
2024-03-24 20:21:30,425 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8645049234231313
2024-03-24 20:21:30,426 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.06751697976142168
2024-03-24 20:21:30,428 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.47395484894514084
2024-03-24 20:21:30,429 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.06818019257237513
2024-03-24 20:21:30,430 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.35238960484297
2024-03-24 20:21:30,431 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7697341505891723
2024-03-24 20:21:30,433 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8751694134460604
2024-03-24 20:21:30,434 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.6030290863871512
2024-03-24 20:21:30,435 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.00845980193879201
2024-03-24 20:21:30,437 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8193086809117855
2024-03-24 20:21:30,438 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.8319176149544241
2024-03-24 20:21:30,439 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 16.122605958987865
2024-03-24 20:21:30,440 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.557951061488076
2024-03-24 20:21:30,441 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 893.802209628904
2024-03-24 20:21:30,442 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 432.55069936773435
2024-03-24 20:21:30,444 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 424.3592115521871
2024-03-24 20:21:30,445 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8659103553453494
2024-03-24 20:21:30,446 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.07402015567801866
2024-03-24 20:21:30,447 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.45874468872248025
2024-03-24 20:21:30,448 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.06462749135525848
2024-03-24 20:22:05,694 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch13.pth ...
2024-03-24 20:22:08,407 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [0/10308 (0%)] Loss: 10.202230
2024-03-24 20:26:29,757 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [900/10308 (9%)] Loss: 9.841162
2024-03-24 20:30:58,147 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [1800/10308 (17%)] Loss: 11.275037
2024-03-24 20:35:46,705 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [2700/10308 (26%)] Loss: 10.571180
2024-03-24 20:40:17,394 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [3600/10308 (35%)] Loss: 12.851071
2024-03-24 20:44:41,063 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [4500/10308 (44%)] Loss: 12.166489
2024-03-24 20:49:14,866 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [5400/10308 (52%)] Loss: 9.741910
2024-03-24 20:53:42,983 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [6300/10308 (61%)] Loss: 11.668442
2024-03-24 20:58:04,673 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [7200/10308 (70%)] Loss: 10.712255
2024-03-24 21:02:42,075 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [8100/10308 (79%)] Loss: 13.196913
2024-03-24 21:07:06,159 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [9000/10308 (87%)] Loss: 10.366906
2024-03-24 21:11:40,645 - PROT.PROT.trainer.trainer - INFO - Train Epoch: 14 [9900/10308 (96%)] Loss: 10.904907
2024-03-24 21:15:03,170 - PROT.PROT.base.base_trainer - INFO - epoch          : 14
2024-03-24 21:15:03,171 - PROT.PROT.base.base_trainer - INFO - loss           : 11.203704671213842
2024-03-24 21:15:03,173 - PROT.PROT.base.base_trainer - INFO - metric_ss8     : 0.7518267681201299
2024-03-24 21:15:03,174 - PROT.PROT.base.base_trainer - INFO - metric_ss3     : 0.8658883919318517
2024-03-24 21:15:03,176 - PROT.PROT.base.base_trainer - INFO - metric_dis_mcc : 0.5763917657701919
2024-03-24 21:15:03,177 - PROT.PROT.base.base_trainer - INFO - metric_dis_fnr : 0.0057906585473877685
2024-03-24 21:15:03,178 - PROT.PROT.base.base_trainer - INFO - metric_rsa     : 0.7996691465377808
2024-03-24 21:15:03,179 - PROT.PROT.base.base_trainer - INFO - metric_asa     : 0.812401627500852
2024-03-24 21:15:03,180 - PROT.PROT.base.base_trainer - INFO - metric_phi     : 17.737794876098633
2024-03-24 21:15:03,181 - PROT.PROT.base.base_trainer - INFO - metric_psi     : 24.337751070658367
2024-03-24 21:15:03,183 - PROT.PROT.base.base_trainer - INFO - metric_tasa    : 670.0697854359945
2024-03-24 21:15:03,184 - PROT.PROT.base.base_trainer - INFO - metric_thsa    : 275.0084171295166
2024-03-24 21:15:03,185 - PROT.PROT.base.base_trainer - INFO - metric_lhp     : 252.1880340576172
2024-03-24 21:15:03,186 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_mcc: 0.8663444916407267
2024-03-24 21:15:03,187 - PROT.PROT.base.base_trainer - INFO - metric_hp_loc_fnr: 0.07508420556162794
2024-03-24 21:15:03,188 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_mcc: 0.47606507937113446
2024-03-24 21:15:03,189 - PROT.PROT.base.base_trainer - INFO - metric_lhp_loc_fnr: 0.06756573015203078
2024-03-24 21:15:03,191 - PROT.PROT.base.base_trainer - INFO - val_loss       : 12.247537451036742
2024-03-24 21:15:03,192 - PROT.PROT.base.base_trainer - INFO - val_metric_ss8 : 0.7711673480118333
2024-03-24 21:15:03,193 - PROT.PROT.base.base_trainer - INFO - val_metric_ss3 : 0.8765521433300638
2024-03-24 21:15:03,194 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_mcc: 0.611203785546829
2024-03-24 21:15:03,195 - PROT.PROT.base.base_trainer - INFO - val_metric_dis_fnr: 0.00999870215084256
2024-03-24 21:15:03,196 - PROT.PROT.base.base_trainer - INFO - val_metric_rsa : 0.8216374700139809
2024-03-24 21:15:03,197 - PROT.PROT.base.base_trainer - INFO - val_metric_asa : 0.834223306926854
2024-03-24 21:15:03,198 - PROT.PROT.base.base_trainer - INFO - val_metric_phi : 15.959309106383376
2024-03-24 21:15:03,199 - PROT.PROT.base.base_trainer - INFO - val_metric_psi : 22.273589260903673
2024-03-24 21:15:03,200 - PROT.PROT.base.base_trainer - INFO - val_metric_tasa: 977.7525013716019
2024-03-24 21:15:03,201 - PROT.PROT.base.base_trainer - INFO - val_metric_thsa: 422.87008070153945
2024-03-24 21:15:03,202 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp : 415.60670299459645
2024-03-24 21:15:03,203 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_mcc: 0.8684857806596369
2024-03-24 21:15:03,204 - PROT.PROT.base.base_trainer - INFO - val_metric_hp_loc_fnr: 0.05845169166560075
2024-03-24 21:15:03,205 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_mcc: 0.4600066225357161
2024-03-24 21:15:03,206 - PROT.PROT.base.base_trainer - INFO - val_metric_lhp_loc_fnr: 0.055661174508217184
2024-03-24 21:15:20,653 - PROT.PROT.base.base_trainer - INFO - Saving checkpoint: saved/basic_w_patches/0324-075325/checkpoints/checkpoint-epoch14.pth ...
2024-03-24 21:15:21,074 - PROT.PROT.main - INFO - Initialising evaluation
2024-03-24 21:15:22,778 - PROT.PROT.base.base_eval - INFO - Starting evaluating...
2024-03-24 21:15:30,027 - PROT.PROT.base.base_eval - INFO - metric_ss8: 0.6824539984975543
2024-03-24 21:15:30,028 - PROT.PROT.base.base_eval - INFO - metric_ss3: 0.7933166367667062
2024-03-24 21:15:30,030 - PROT.PROT.base.base_eval - INFO - metric_dis_mcc: 0.5684286185673305
2024-03-24 21:15:30,031 - PROT.PROT.base.base_eval - INFO - metric_dis_fnr: 0.03357013000641018
2024-03-24 21:15:30,032 - PROT.PROT.base.base_eval - INFO - metric_rsa: 0.7227356689316886
2024-03-24 21:15:30,033 - PROT.PROT.base.base_eval - INFO - metric_asa: 0.7384815301213946
2024-03-24 21:15:30,035 - PROT.PROT.base.base_eval - INFO - metric_phi: 20.420861652919225
2024-03-24 21:15:30,036 - PROT.PROT.base.base_eval - INFO - metric_psi: 31.823296410696848
2024-03-24 21:15:30,037 - PROT.PROT.base.base_eval - INFO - metric_tasa: 1436.5144566127233
2024-03-24 21:15:30,039 - PROT.PROT.base.base_eval - INFO - metric_thsa: 906.0503867013114
2024-03-24 21:15:30,040 - PROT.PROT.base.base_eval - INFO - metric_lhp: 463.5335170200893
2024-03-24 21:15:30,041 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_mcc: 0.8546218616621835
2024-03-24 21:15:30,042 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_fnr: 0.054732538759708405
2024-03-24 21:15:30,043 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_mcc: 0.47648036054202486
2024-03-24 21:15:30,044 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_fnr: 0.03290240825819118
2024-03-24 21:15:31,741 - PROT.PROT.base.base_eval - INFO - Starting evaluating...
2024-03-24 21:16:45,208 - PROT.PROT.base.base_eval - INFO - metric_ss8: 0.7350359294149611
2024-03-24 21:16:45,212 - PROT.PROT.base.base_eval - INFO - metric_ss3: 0.8662642327665585
2024-03-24 21:16:45,213 - PROT.PROT.base.base_eval - INFO - metric_dis_mcc: 0.08430376583609082
2024-03-24 21:16:45,215 - PROT.PROT.base.base_eval - INFO - metric_dis_fnr: 0.01640937687714764
2024-03-24 21:16:45,216 - PROT.PROT.base.base_eval - INFO - metric_rsa: 0.8149454483860418
2024-03-24 21:16:45,217 - PROT.PROT.base.base_eval - INFO - metric_asa: 0.8277460280914752
2024-03-24 21:16:45,219 - PROT.PROT.base.base_eval - INFO - metric_phi: 18.877215987757634
2024-03-24 21:16:45,220 - PROT.PROT.base.base_eval - INFO - metric_psi: 25.505420182880602
2024-03-24 21:16:45,221 - PROT.PROT.base.base_eval - INFO - metric_tasa: 1008.2580650284973
2024-03-24 21:16:45,223 - PROT.PROT.base.base_eval - INFO - metric_thsa: 428.74428678813734
2024-03-24 21:16:45,224 - PROT.PROT.base.base_eval - INFO - metric_lhp: 431.6374853033769
2024-03-24 21:16:45,225 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_mcc: 0.8647738249862895
2024-03-24 21:16:45,226 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_fnr: 0.04946914665839251
2024-03-24 21:16:45,227 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_mcc: 0.4445227090952664
2024-03-24 21:16:45,229 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_fnr: 0.042017513357058785
2024-03-24 21:16:46,816 - PROT.PROT.base.base_eval - INFO - Starting evaluating...
2024-03-24 21:17:07,574 - PROT.PROT.base.base_eval - INFO - metric_ss8: 0.7648197199987329
2024-03-24 21:17:07,576 - PROT.PROT.base.base_eval - INFO - metric_ss3: 0.8691128067348315
2024-03-24 21:17:07,577 - PROT.PROT.base.base_eval - INFO - metric_dis_mcc: 0.6511601665421672
2024-03-24 21:17:07,578 - PROT.PROT.base.base_eval - INFO - metric_dis_fnr: 0.018678788339678683
2024-03-24 21:17:07,580 - PROT.PROT.base.base_eval - INFO - metric_rsa: 0.7973398545513982
2024-03-24 21:17:07,581 - PROT.PROT.base.base_eval - INFO - metric_asa: 0.81602906714315
2024-03-24 21:17:07,582 - PROT.PROT.base.base_eval - INFO - metric_phi: 16.418760200168776
2024-03-24 21:17:07,583 - PROT.PROT.base.base_eval - INFO - metric_psi: 23.428041740085767
2024-03-24 21:17:07,585 - PROT.PROT.base.base_eval - INFO - metric_tasa: 977.5877314028533
2024-03-24 21:17:07,586 - PROT.PROT.base.base_eval - INFO - metric_thsa: 429.7916785198709
2024-03-24 21:17:07,587 - PROT.PROT.base.base_eval - INFO - metric_lhp: 515.4862309994905
2024-03-24 21:17:07,588 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_mcc: 0.869357344896897
2024-03-24 21:17:07,589 - PROT.PROT.base.base_eval - INFO - metric_hp_loc_fnr: 0.04530897193952747
2024-03-24 21:17:07,591 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_mcc: 0.4724599980789682
2024-03-24 21:17:07,592 - PROT.PROT.base.base_eval - INFO - metric_lhp_loc_fnr: 0.047702737938126794
2024-03-24 21:17:07,594 - PROT.PROT.main - INFO - Finished!
done
